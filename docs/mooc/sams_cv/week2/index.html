<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Строим первую нейронную сеть #  Восстановление зависимостей #  Размеченная обучающая выборка состоит из объектов, для которых мы знаем:
 некоторые признаки метку объекта  Хорошей практикой является разделение датасета на три поддатасета:
 train (используется непосредственно для обучения модели) valid (используется для подстраивания параметров обучения нашей модели) test (используется для проверки окончательного результата)  Компоненты нейронной сети #   Архитектура нейронной сети Функции потерь (способ определения результата работы создаваемой сети; минимум этой функции соответствует оптимально настроенной сети) Метод оптимизации (говорит о том, как именно нужно изменить настройки сети для минимизации функции потерь) Метрики (показывают насколько успешно сеть решает поставленную задачу; например: точность; в отличии от функции потерь могут быть не дифференцируемыми)  Результирующая зависимость - сумма сигмоидных функций с соответствующими параметрами."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Строим первую нейронную сеть"><meta property="og:description" content="Строим первую нейронную сеть #  Восстановление зависимостей #  Размеченная обучающая выборка состоит из объектов, для которых мы знаем:
 некоторые признаки метку объекта  Хорошей практикой является разделение датасета на три поддатасета:
 train (используется непосредственно для обучения модели) valid (используется для подстраивания параметров обучения нашей модели) test (используется для проверки окончательного результата)  Компоненты нейронной сети #   Архитектура нейронной сети Функции потерь (способ определения результата работы создаваемой сети; минимум этой функции соответствует оптимально настроенной сети) Метод оптимизации (говорит о том, как именно нужно изменить настройки сети для минимизации функции потерь) Метрики (показывают насколько успешно сеть решает поставленную задачу; например: точность; в отличии от функции потерь могут быть не дифференцируемыми)  Результирующая зависимость - сумма сигмоидных функций с соответствующими параметрами."><meta property="og:type" content="article"><meta property="og:url" content="https://morggoth.github.io/docs/mooc/sams_cv/week2/"><meta property="article:published_time" content="2019-12-12T00:45:53+03:00"><meta property="article:modified_time" content="2019-12-12T00:45:53+03:00"><title>Строим первую нейронную сеть | Morggoth's wiki</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.6cd8553a6854f4812343f0f0c8baca31271e686434f381fbe3c7226f66639176.css integrity="sha256-bNhVOmhU9IEjQ/DwyLrKMSceaGQ084H748cib2ZjkXY="><script defer src=/en.search.min.a4e92e1c70f88bfb675d7d6808aa6b543166b2fe9d0d4d8fd5155138c59ac2bb.js integrity="sha256-pOkuHHD4i/tnXX1oCKprVDFmsv6dDU2P1RVROMWawrs="></script></head><body><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><h2 class=book-brand><a href=/><span>Morggoth's wiki</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/docs/cloud/ class=collapsed>Cloud</a></li><li><a href=/docs/k8s/ class=collapsed>Kubernetes</a></li><li><a href=/docs/mooc/ class=collapsed>Courses notes</a><ul><li><a href=/docs/mooc/astronomer/>Apache Airflow fundamentals</a></li><li><a href=/docs/mooc/datastax_academy/cassandra_operations/>DS210: DataStax Enterprise 6 Operations with Apache Cassandra™</a></li><li><a href=/docs/mooc/datastax_academy/casandra_foundations/>DS201: DataStax Enterprise 6 Foundations of Apache Cassandra™</a></li><li><a href=/docs/mooc/math/ class=collapsed>Книга для чтения по высшей математике</a></li><li><a href=/docs/mooc/ml/>Машинное обучение</a></li><li><a href=/docs/mooc/sams_cv/ class=collapsed>Нейронные сети и компьютерное зрение</a><ul><li><a href=/docs/mooc/sams_cv/week1/>Нейрон и нейронная сеть</a></li><li><a href=/docs/mooc/sams_cv/week2/ class=active>Строим первую нейронную сеть</a></li></ul></li></ul></li><li><a href=/docs/misc/docker/>Основы Docker</a></li><li><a href=/docs/misc/cheatsheets/>Cheatsheets</a></li><li><a href=/docs/misc/rpi/>Raspberry Pi</a></li><li><a href=/docs/misc/kafka/>Kafka basics</a></li><li><a href=/docs/misc/old_hardware/>Old hardware</a></li><li><a href=/docs/languages/ class=collapsed>Languages</a></li><li><a href=/docs/misc/chromeos/>ChromeOS</a></li><li><a href=/docs/misc/macos/>macOS</a></li><li><a href=/docs/misc/mikrotik/>Mikrotik</a></li><li><a href=/docs/misc/tips_and_tricks/>Tips & Tricks</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Строим первую нейронную сеть</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#восстановление-зависимостей>Восстановление зависимостей</a></li><li><a href=#компоненты-нейронной-сети>Компоненты нейронной сети</a><ul><li><a href=#функция-потерь>Функция потерь</a></li></ul></li><li><a href=#алгоритмы-настройки-нейронной-сети>Алгоритмы настройки нейронной сети</a><ul><li><a href=#градиентный-спуск>Градиентный спуск</a></li><li><a href=#правило-цепочки-правило-производной-сложной-функции>Правило цепочки (правило производной сложной функции)</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=строим-первую-нейронную-сеть>Строим первую нейронную сеть
<a class=anchor href=#%d1%81%d1%82%d1%80%d0%be%d0%b8%d0%bc-%d0%bf%d0%b5%d1%80%d0%b2%d1%83%d1%8e-%d0%bd%d0%b5%d0%b9%d1%80%d0%be%d0%bd%d0%bd%d1%83%d1%8e-%d1%81%d0%b5%d1%82%d1%8c>#</a></h1><h2 id=восстановление-зависимостей>Восстановление зависимостей
<a class=anchor href=#%d0%b2%d0%be%d1%81%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5-%d0%b7%d0%b0%d0%b2%d0%b8%d1%81%d0%b8%d0%bc%d0%be%d1%81%d1%82%d0%b5%d0%b9>#</a></h2><p>Размеченная обучающая выборка состоит из объектов, для которых мы знаем:</p><ul><li>некоторые признаки</li><li>метку объекта</li></ul><p>Хорошей практикой является разделение датасета на три поддатасета:</p><ul><li>train (используется непосредственно для обучения модели)</li><li>valid (используется для подстраивания параметров обучения нашей модели)</li><li>test (используется для проверки окончательного результата)</li></ul><h2 id=компоненты-нейронной-сети>Компоненты нейронной сети
<a class=anchor href=#%d0%ba%d0%be%d0%bc%d0%bf%d0%be%d0%bd%d0%b5%d0%bd%d1%82%d1%8b-%d0%bd%d0%b5%d0%b9%d1%80%d0%be%d0%bd%d0%bd%d0%be%d0%b9-%d1%81%d0%b5%d1%82%d0%b8>#</a></h2><ul><li>Архитектура нейронной сети</li><li>Функции потерь (способ определения результата работы создаваемой сети; минимум этой функции соответствует оптимально настроенной сети)</li><li>Метод оптимизации (говорит о том, как именно нужно изменить настройки сети для минимизации функции потерь)</li><li>Метрики (показывают насколько успешно сеть решает поставленную задачу; например: точность; в отличии от функции потерь могут быть не дифференцируемыми)</li></ul><p>Результирующая зависимость - сумма сигмоидных функций с соответствующими параметрами.</p><h3 id=функция-потерь>Функция потерь
<a class=anchor href=#%d1%84%d1%83%d0%bd%d0%ba%d1%86%d0%b8%d1%8f-%d0%bf%d0%be%d1%82%d0%b5%d1%80%d1%8c>#</a></h3><p>Для задач восстановления скрытых зависимостей зачастую в качестве функции потерь используют функцию среднего квадрата ошибки (MSE, mean squared error):</p><pre><code class=language-math data-lang=math>MSE=(1/N)*sum_N_i=1(y_av_i - y_i)^2
</code></pre><p>где:</p><ul><li>y_av_i - результат работы сети</li><li>y_i - целевые значения</li></ul><p>То есть это сумма квадратов отклонения полученных результатов от ожидаемых значений.</p><h2 id=алгоритмы-настройки-нейронной-сети>Алгоритмы настройки нейронной сети
<a class=anchor href=#%d0%b0%d0%bb%d0%b3%d0%be%d1%80%d0%b8%d1%82%d0%bc%d1%8b-%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b8-%d0%bd%d0%b5%d0%b9%d1%80%d0%be%d0%bd%d0%bd%d0%be%d0%b9-%d1%81%d0%b5%d1%82%d0%b8>#</a></h2><h3 id=градиентный-спуск>Градиентный спуск
<a class=anchor href=#%d0%b3%d1%80%d0%b0%d0%b4%d0%b8%d0%b5%d0%bd%d1%82%d0%bd%d1%8b%d0%b9-%d1%81%d0%bf%d1%83%d1%81%d0%ba>#</a></h3><p>w0 - вектор весов, который содержит все значения весов и смещений, которые используются в сети.</p><p>Градиент функции потерь - вектор, состоящий из производных по каждой из координат функции.
Градиент указывает в сторону наибольшего роста функции потерь => требуется сделать шаг из точки w0 в направлении обратном направлению градиента.
Далее шаги повторяются.</p><p>Градиентный спуск находит минимум функции, но не гарантирует нахождения оптимального минимума.</p><p>Ограничения, накладываемые на функцию потерь:</p><ul><li>должна быть дифференцируемой (если в некотором множестве точек производная не определена, ее можно доопределить)</li><li>производная функции потерь не должна быть равна нулю в большинстве точек</li></ul><h3 id=правило-цепочки-правило-производной-сложной-функции>Правило цепочки (правило производной сложной функции)
<a class=anchor href=#%d0%bf%d1%80%d0%b0%d0%b2%d0%b8%d0%bb%d0%be-%d1%86%d0%b5%d0%bf%d0%be%d1%87%d0%ba%d0%b8-%d0%bf%d1%80%d0%b0%d0%b2%d0%b8%d0%bb%d0%be-%d0%bf%d1%80%d0%be%d0%b8%d0%b7%d0%b2%d0%be%d0%b4%d0%bd%d0%be%d0%b9-%d1%81%d0%bb%d0%be%d0%b6%d0%bd%d0%be%d0%b9-%d1%84%d1%83%d0%bd%d0%ba%d1%86%d0%b8%d0%b8>#</a></h3><p>Граф вычисления - порядок вычисления сложной функции.</p><p><a href="https://stepik.org/lesson/210594/step/6?unit=184089">пересмотреть</a></p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#восстановление-зависимостей>Восстановление зависимостей</a></li><li><a href=#компоненты-нейронной-сети>Компоненты нейронной сети</a><ul><li><a href=#функция-потерь>Функция потерь</a></li></ul></li><li><a href=#алгоритмы-настройки-нейронной-сети>Алгоритмы настройки нейронной сети</a><ul><li><a href=#градиентный-спуск>Градиентный спуск</a></li><li><a href=#правило-цепочки-правило-производной-сложной-функции>Правило цепочки (правило производной сложной функции)</a></li></ul></li></ul></nav></aside></main></body></html>