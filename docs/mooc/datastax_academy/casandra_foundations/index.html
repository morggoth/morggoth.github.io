<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="# How to start bin/cassandra # for core version ./dse cassandra # for DSE version bin/nodetool status # provide with cluster health info CQL Fundamentals #  -- CQL - very similar to SQL SELECT * FROM USERS; -- Keyspaces - very similar to schemas in RDBMS; it is top level namespace/container; replication parameters required; contains tables CREATE KEYSPACE some_keyspace WITH REPLICATION = { 'class': 'SimpleStrategy', 'replication_factor': 1 }; -- USE switches between keyspaces USE other_keyspace; -- Tables contain data CREATE TABLE table1 ( column1 TEXT, column2 TEXT, column3 INT, PRIMARY KEY (column1) ); -- INSERT syntax similar to SQL syntax INSERT INTO users (user_id, first_name, last_name) VALUES (uuid(), 'John', 'Doe') -- SELECT also similar to SQL syntax SELECT * FROM users; SELECT first_name, last_name FROM users; SELECT * FROM users WHERE user_id = some_uuid_value; -- COPY - uses to import/export data between tables and CSV files COPY table1 (column1, column2, column3) FROM 'table1data."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="DS201: DataStax Enterprise 6 Foundations of Apache Cassandra™"><meta property="og:description" content="# How to start bin/cassandra # for core version ./dse cassandra # for DSE version bin/nodetool status # provide with cluster health info CQL Fundamentals #  -- CQL - very similar to SQL SELECT * FROM USERS; -- Keyspaces - very similar to schemas in RDBMS; it is top level namespace/container; replication parameters required; contains tables CREATE KEYSPACE some_keyspace WITH REPLICATION = { 'class': 'SimpleStrategy', 'replication_factor': 1 }; -- USE switches between keyspaces USE other_keyspace; -- Tables contain data CREATE TABLE table1 ( column1 TEXT, column2 TEXT, column3 INT, PRIMARY KEY (column1) ); -- INSERT syntax similar to SQL syntax INSERT INTO users (user_id, first_name, last_name) VALUES (uuid(), 'John', 'Doe') -- SELECT also similar to SQL syntax SELECT * FROM users; SELECT first_name, last_name FROM users; SELECT * FROM users WHERE user_id = some_uuid_value; -- COPY - uses to import/export data between tables and CSV files COPY table1 (column1, column2, column3) FROM 'table1data."><meta property="og:type" content="article"><meta property="og:url" content="https://morggoth.github.io/docs/mooc/datastax_academy/casandra_foundations/"><meta property="article:published_time" content="2020-07-01T22:32:41+03:00"><meta property="article:modified_time" content="2020-07-01T22:32:41+03:00"><title>DS201: DataStax Enterprise 6 Foundations of Apache Cassandra™ | Morggoth's wiki</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.6cd8553a6854f4812343f0f0c8baca31271e686434f381fbe3c7226f66639176.css integrity="sha256-bNhVOmhU9IEjQ/DwyLrKMSceaGQ084H748cib2ZjkXY="><script defer src=/en.search.min.a488ebbd83098e77cdc813195a091b32b5559c8e976de72442b1ee110e6939a6.js integrity="sha256-pIjrvYMJjnfNyBMZWgkbMrVVnI6XbeckQrHuEQ5pOaY="></script></head><body><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><h2 class=book-brand><a href=/><span>Morggoth's wiki</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/docs/misc/cheatsheets/>Cheatsheets</a></li><li><a href=/docs/misc/rpi/>Raspberry Pi</a></li><li><a href=/docs/misc/kafka/>Kafka basics</a></li><li><a href=/docs/mooc/ class=collapsed>Courses notes</a><ul><li><a href=/docs/mooc/datastax_academy/cassandra_operations/>DS210: DataStax Enterprise 6 Operations with Apache Cassandra™</a></li><li><a href=/docs/mooc/datastax_academy/casandra_foundations/ class=active>DS201: DataStax Enterprise 6 Foundations of Apache Cassandra™</a></li><li><a href=/docs/mooc/foundation_of_kubernetes/>Foundation of Kubernetes</a></li><li><a href=/docs/mooc/math/ class=collapsed>Книга для чтения по высшей математике</a></li><li><a href=/docs/mooc/ml/>Машинное обучение</a></li><li><a href=/docs/mooc/sams_cv/ class=collapsed>Нейронные сети и компьютерное зрение</a></li></ul></li><li><a href=/docs/misc/old_hardware/>Old hardware</a></li><li><a href=/docs/languages/ class=collapsed>Languages</a></li><li><a href=/docs/misc/chromeos/>ChromeOS</a></li><li><a href=/docs/misc/macos/>macOS</a></li><li><a href=/docs/misc/mikrotik/>Mikrotik</a></li><li><a href=/docs/misc/tips_and_tricks/>Tips & Tricks</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>DS201: DataStax Enterprise 6 Foundations of Apache Cassandra™</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#cql-fundamentals>CQL Fundamentals</a><ul><li><a href=#core-datatypes>Core datatypes</a></li></ul></li><li><a href=#partitions>Partitions</a></li><li><a href=#clustering-columns>Clustering columns</a><ul><li><a href=#changing-default-ordering>Changing default ordering</a></li></ul></li><li><a href=#node>Node</a><ul><li><a href=#nodetool>Nodetool</a></li></ul></li><li><a href=#ring>Ring</a><ul><li><a href=#joining-the-cluster>Joining the Cluster</a></li><li><a href=#drivers>Drivers</a></li></ul></li><li><a href=#vnodes>Vnodes</a></li><li><a href=#gossip>Gossip</a></li><li><a href=#snitch>Snitch</a><ul><li><a href=#configuring-snitches>Configuring snitches</a></li></ul></li><li><a href=#replication>Replication</a></li><li><a href=#consistency>Consistency</a></li><li><a href=#hinted-handoff>Hinted handoff</a></li><li><a href=#read-repair>Read repair</a><ul><li><a href=#nodetool-repair>Nodetool repair</a></li></ul></li><li><a href=#node-sync>Node sync</a></li><li><a href=#write-path>Write path</a></li><li><a href=#read-path>Read path</a><ul><li><a href=#bloom-filter>Bloom filter</a></li><li><a href=#dse-read-path-optimizations>DSE Read Path Optimizations</a></li></ul></li><li><a href=#compactions>Compactions</a><ul><li><a href=#compaction-strategies>Compaction strategies</a></li></ul></li></ul></nav></aside></header><article class=markdown><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># How to start</span>
bin/cassandra     <span style=color:#75715e># for core version</span>
./dse cassandra   <span style=color:#75715e># for DSE version</span>

bin/nodetool status    <span style=color:#75715e># provide with cluster health info</span>
</code></pre></div><h2 id=cql-fundamentals>CQL Fundamentals
<a class=anchor href=#cql-fundamentals>#</a></h2><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#75715e>-- CQL - very similar to SQL
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span> <span style=color:#66d9ef>FROM</span> USERS;

<span style=color:#75715e>-- Keyspaces - very similar to schemas in RDBMS; it is top level namespace/container; replication parameters required; contains tables
</span><span style=color:#75715e></span><span style=color:#66d9ef>CREATE</span> KEYSPACE some_keyspace
<span style=color:#66d9ef>WITH</span> REPLICATION <span style=color:#f92672>=</span> <span style=color:#960050;background-color:#1e0010>{</span>
    <span style=color:#e6db74>&#39;class&#39;</span>: <span style=color:#e6db74>&#39;SimpleStrategy&#39;</span>,
    <span style=color:#e6db74>&#39;replication_factor&#39;</span>: <span style=color:#ae81ff>1</span>
<span style=color:#960050;background-color:#1e0010>}</span>;

<span style=color:#75715e>-- USE switches between keyspaces
</span><span style=color:#75715e></span>USE other_keyspace;

<span style=color:#75715e>-- Tables contain data
</span><span style=color:#75715e></span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> table1 (
    column1 TEXT,
    column2 TEXT,
    column3 INT,
    <span style=color:#66d9ef>PRIMARY</span> <span style=color:#66d9ef>KEY</span> (column1)
);

<span style=color:#75715e>-- INSERT syntax similar to SQL syntax
</span><span style=color:#75715e></span><span style=color:#66d9ef>INSERT</span> <span style=color:#66d9ef>INTO</span> users (user_id, first_name, last_name)
<span style=color:#66d9ef>VALUES</span> (uuid(), <span style=color:#e6db74>&#39;John&#39;</span>, <span style=color:#e6db74>&#39;Doe&#39;</span>)

<span style=color:#75715e>-- SELECT also similar to SQL syntax
</span><span style=color:#75715e></span><span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span>
<span style=color:#66d9ef>FROM</span> users;

<span style=color:#66d9ef>SELECT</span> first_name, last_name
<span style=color:#66d9ef>FROM</span> users;

<span style=color:#66d9ef>SELECT</span> <span style=color:#f92672>*</span>
<span style=color:#66d9ef>FROM</span> users
<span style=color:#66d9ef>WHERE</span> user_id <span style=color:#f92672>=</span> some_uuid_value;

<span style=color:#75715e>-- COPY - uses to import/export data between tables and CSV files
</span><span style=color:#75715e></span><span style=color:#66d9ef>COPY</span> table1 (column1, column2, column3) <span style=color:#66d9ef>FROM</span> <span style=color:#e6db74>&#39;table1data.csv&#39;</span>;
<span style=color:#75715e>-- Header parameter skips the first line in the file
</span><span style=color:#75715e></span><span style=color:#66d9ef>COPY</span> table1 (column1, column2, column3) <span style=color:#66d9ef>FROM</span> <span style=color:#e6db74>&#39;table1data.csv&#39;</span>
<span style=color:#66d9ef>WITH</span> HEADER<span style=color:#f92672>=</span><span style=color:#66d9ef>true</span>;

<span style=color:#75715e>-- TRUNCATE - removes table
</span><span style=color:#75715e></span><span style=color:#66d9ef>TRUNCATE</span> <span style=color:#66d9ef>table</span>;

<span style=color:#75715e>-- Get info about table
</span><span style=color:#75715e></span><span style=color:#66d9ef>DESCRIBE</span> <span style=color:#66d9ef>table</span>;
</code></pre></div><h3 id=core-datatypes>Core datatypes
<a class=anchor href=#core-datatypes>#</a></h3><ul><li>text:<ul><li>UTF8 encoded strings</li><li>varchar is same as text</li></ul></li><li>int:<ul><li>signed</li><li>32 bits</li></ul></li><li>timestamps:<ul><li>date and time</li><li>64 bit integer</li><li>stores number of seconds in UNIX epoch</li></ul></li><li>UUID<ul><li>generate via uuid()</li></ul></li><li>TIMEUUID<ul><li>contains timestamp value</li><li>sortable</li><li>generate via now()</li></ul></li></ul><p>UUID and TIMEUUID - used place of integer IDs because Cassandra is a distributed DB</p><h2 id=partitions>Partitions
<a class=anchor href=#partitions>#</a></h2><p>Tables sorted by partition key and splited for parts by its value over the cluster nodes.
Partition key - first value of primary key</p><h2 id=clustering-columns>Clustering columns
<a class=anchor href=#clustering-columns>#</a></h2><p>This is other half of primary key; they used for sorting data in partitions</p><blockquote><p>Primary key - is the most important part of your data model in Cassandra</p></blockquote><p>You can&rsquo;t change primary key if you already have data in table, because in this case you need to redo your data model</p><p>There might be multiple cluster columns in table</p><p>To prevent collisions, also need to add to the primary key some uuid field.</p><p>Every query should have a pertition key</p><p>You can perform either equality (=) or range queries (&lt;, >) in clustering columns</p><p>All equality comparisons must come before inequality comparisons</p><p>Since data is sorted on disk, range searches are a binary search followed by a linear read</p><h3 id=changing-default-ordering>Changing default ordering
<a class=anchor href=#changing-default-ordering>#</a></h3><p>By default clustering columns ordered by ascending</p><p>Change ordering direction via WITH CLUSTERING ORDER BY</p><p>Must include all columns including an up to the columns you wish to order descending</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> users (
    <span style=color:#66d9ef>state</span> text,
    city text,
    name textm
    id uuid,
    <span style=color:#66d9ef>PRIMARY</span> <span style=color:#66d9ef>KEY</span>((<span style=color:#66d9ef>state</span>), sity, name, id))
    <span style=color:#66d9ef>WITH</span> CLUSTERING <span style=color:#66d9ef>ORDER</span> <span style=color:#66d9ef>BY</span> (city <span style=color:#66d9ef>DESC</span>, name <span style=color:#66d9ef>ASC</span>);
)
</code></pre></div><h2 id=node>Node
<a class=anchor href=#node>#</a></h2><p>This is strongly recommend to store Casandra data on the local storage, not on SAN (or sort of)</p><p>Node stores all data in distributed hash tables</p><p>Approximate performance of one node - 6000 - 12000 transactions/second/core.
Also, one node can effectively store - 2-4 TB of data</p><h3 id=nodetool>Nodetool
<a class=anchor href=#nodetool>#</a></h3><p>Tool for node management. Located in <em>${install_root}/bin/</em></p><p>Sub-commands:</p><ul><li>help</li><li>info</li><li>status</li><li>describecluster</li><li>getlogginglevels</li><li>setlogginglevel</li><li>settraceprobability 0.1</li><li>drain</li><li>stopdaemon</li><li>flush</li></ul><h2 id=ring>Ring
<a class=anchor href=#ring>#</a></h2><p>Ring - name of Cassandra cluster.</p><p>Each node handle specific range of all stored in a cluster data.
Coordinator - node, which receives data from a client and after that it transmit data to the node,
which handle right range,</p><h3 id=joining-the-cluster>Joining the Cluster
<a class=anchor href=#joining-the-cluster>#</a></h3><p>Nodes join the cluster by communicating with any node.
Cassandra finds these <em>seed nodes</em> list of possible nodes in <em>cassandra.yaml</em>
Seed nodes communicate cluster topology to the joining node.
Node the new node joins the cluster, all nodes are peers.</p><p>Node states:</p><ul><li>joining</li><li>leaving</li><li>up</li><li>down</li></ul><h3 id=drivers>Drivers
<a class=anchor href=#drivers>#</a></h3><p>Drivers may choose which node would base coordinate a request</p><p>Diver policies:</p><ul><li>TokenAwarePolicy - driver chooses node which contains the data</li><li>RoundRobin - driver round robin the ring</li><li>DCAwareRoundRobinPolicy - driver round robins the target data center</li></ul><h2 id=vnodes>Vnodes
<a class=anchor href=#vnodes>#</a></h2><p>With Vnodes, each node is now responsible for multiple smaller slices of the ring, instead of the one large slice.</p><p>When new node joins to the ring, each current node streams few slices to it in parallel. And now the new node will responsible for this slices.</p><p>Adding/removing nodes with vnodes helps keep the cluster balanced.
By default, each node has 128 vnodes.
VNodes automate token ring assignment.</p><p>Number of vnodes may be configured in <em>cassandra.yaml</em> with <em>num_tokens</em> parameter. Each value greater than one turns on vnodes.</p><h2 id=gossip>Gossip
<a class=anchor href=#gossip>#</a></h2><p>Gossit - broadcast protocol</p><ul><li>Each node initiates a gossip round every second</li><li>pick on to three nodes to gossip with</li><li>nodes can gossip with ANY other node in the cluster</li><li>fault tolerant - continues to spread when nodes fail</li></ul><p>Gossip spreads only node metadata, not the client data.</p><p>Endpoint State:</p><ul><li><p>Heartbeat State:</p><ul><li>generation (time since node bootstrapped)</li><li>version (increments every second after gossip with ather node)</li></ul></li><li><p>Application State (stores node metadata):</p><ul><li>STATUS:<ul><li>BOOTSTRAP</li><li>NORMAL</li><li>LEAVING</li><li>LEFT</li><li>REMOVING</li><li>REMOVED</li></ul></li><li>DC (datacenter)</li><li>RACK</li><li>SCHEMA (number of schema changes)</li><li>LOAD (disk space usage)</li><li>etc</li></ul></li><li><p>SYN digest schema - endpoint_ip:generation:version (i.e. 127.0.0.1:100:20)</p></li><li><p>ACK also stores digest of outdated info</p></li><li><p>ACK2 - send only updated info.</p></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>nodetool gossipinfo
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>SELECT</span> peer, data_center, host_id, preferred_ip, rack, release_version, rpc_address, schema_version
<span style=color:#66d9ef>FROM</span> <span style=color:#66d9ef>system</span>.peers;
</code></pre></div><h2 id=snitch>Snitch
<a class=anchor href=#snitch>#</a></h2><ul><li>Determines/declares each node&rsquo;s rack and data center</li><li>The &ldquo;topology&rdquo; of the cluster</li></ul><p>There are several types of snitches:</p><ul><li>Regular:<ul><li>SimpleSnitch<ul><li>default snitch</li><li>places all nodes in the same datacenter and rack (datacenter1 and rack1)</li></ul></li><li>PropertyFileSnitch<ul><li>reads dc and rack info for all nodes from a file</li><li>you must keep files in sync with all nodes in the cluster</li><li><em>cassandra-topology.properties</em> file</li></ul></li><li>GossipingPropertyFileSnutch (the most popular type)<ul><li>declare the current node&rsquo;s DC/Rack info in a file</li><li>you must set each individual node&rsquo;s settings</li><li>but you don&rsquo;t have to copy settings as with property file snitch</li><li>Gossip spreads the settings through the cluster</li><li><em>cassandra-rackdc.properties</em> file</li></ul></li><li>RackInferringSnitch<ul><li>infers the rack and DB from the IP address:<ul><li>2nd octet is DB octet</li><li>3rd - rack octet</li><li>4th - node octet</li></ul></li></ul></li><li>DynamicSnitch<ul><li>layered on top of your actual snitch</li><li>maitains a pulse of each node&rsquo;s performance</li><li>determones which node to query replicas from depending on node health</li><li>turned on by default for all snitches</li></ul></li></ul></li><li>Cloud Based:<ul><li>Ec2Snitch</li><li>Ec2MultiRegionSnitch</li><li>GoogleCloudSnitch</li><li>CloudstackSnitch</li></ul></li></ul><p>Configured on <em>cassandra.yaml</em>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#f92672>endpoint_snitch</span>: <span style=color:#ae81ff>SimpleSnitch</span>
</code></pre></div><h3 id=configuring-snitches>Configuring snitches
<a class=anchor href=#configuring-snitches>#</a></h3><ul><li>All nodes in the cluster must ust the same snotch</li><li>Changing cluster network topology requires rastarting all nodes</li><li>Run sequential repair and clean up on each node</li></ul><h2 id=replication>Replication
<a class=anchor href=#replication>#</a></h2><p>With replication factor (RF) 2, each node stores not only its own data, but also its neighbour data.
And in this case, coordinator writes data on two nodes.</p><p>With RF=3, each node stores also data of the neighbour of the neighbour.</p><h2 id=consistency>Consistency
<a class=anchor href=#consistency>#</a></h2><p>CAP theorem; Cassandra choose Partition Tolerance and Availability.</p><p>Consistency levels - number of acknowledges from the target node to the coordinator during the data writing.</p><ul><li>any (storing a hit at minimum is satisfactory)</li><li>one, two, three</li><li>quorum</li><li>local_one (the closest node to coordinator in the same dc)</li><li>local_quorum (only for one dc)</li><li>each_quorum (quorum of nodes in each dc, applies to write only)</li><li>all</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#75715e>-- cql operator/cqlsh command
</span><span style=color:#75715e></span>CONSISTENCY
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># determine which nodes hold the replicas of the partition tag</span>
nodetool getendpoints keyspace_name table_name <span style=color:#e6db74>&#39;partition_key_name&#39;</span>
</code></pre></div><h2 id=hinted-handoff>Hinted handoff
<a class=anchor href=#hinted-handoff>#</a></h2><p>If replica node is down, coordinator stores the data until replica will back online.</p><p>Settings:</p><ul><li>cassandra.yaml</li><li>you can disable hinted handoff</li><li>choose a directory to store hints file</li><li>set the amount of time a node will store a hint</li><li>default is three hours</li></ul><h2 id=read-repair>Read repair
<a class=anchor href=#read-repair>#</a></h2><p>With Cassandra, you can choose between absolutely synced with each others node and highly available nodes.</p><p>Read with CL=all:</p><ul><li>coordinator reads data from the closest node and request digest (data&rsquo;s checksum) from others replicas</li><li>coordinator compares data and checksums and if they equal, sends data to the client.</li><li>if checksums don&rsquo;t compare:<ul><li>coordinator finds out a timestamp from received data</li><li>requests full data from all replicas to compare its timestamps</li><li>after finding the latest version of data, coordinator sends it to the outdated replicas and to the client.</li></ul></li></ul><p>Read repair chance:</p><ul><li>performed when read is at a consistency level less then ALL</li><li>request reads only a subset of the replicas</li><li>we can&rsquo;t be sure replicas are in sync</li><li>generally you are safe, but no guarantees</li><li>response sent immediately when consistence level is met</li><li>read repair done asynchronously in the background</li><li>dclocal_read_repair_chance set to 0.1 (10%) by default<ul><li>read repair that is confined to the same DC as the coordinator node</li></ul></li><li>read_repair_chance set to 0 by default<ul><li>for a read repair across all DCs with replicas</li></ul></li></ul><h3 id=nodetool-repair>Nodetool repair
<a class=anchor href=#nodetool-repair>#</a></h3><ul><li>syncs all data in the cluster</li><li>expensive<ul><li>grows with an amount of data in cluster</li></ul></li><li>use with a cluster servicing high writes/deletes</li><li>last line of defense</li><li>run to synchronize a failed node coming back online</li><li>run on nodes not read from very often</li></ul><h2 id=node-sync>Node sync
<a class=anchor href=#node-sync>#</a></h2><p>Full repairs:</p><ul><li>full repairs bog down the system</li><li>bigger the cluster and dataset. the worse the time</li><li>in times past, we recommended running full repair within <em>gc_grace_seconds</em></li></ul><p>Node sync:</p><ul><li>Runs on the background continuously repairing you data<ul><li>quiet hub vs everybody stops what you&rsquo;re doing</li></ul></li><li>better to repair in small chunks as we go rather than full repair</li><li>automatic enabled by default (in DataStax version)<ul><li>by you must enable it per table</li></ul></li><li>each node runs NodeSync</li><li>NodeSync continuously validates and repairs data</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> myTable (...)
<span style=color:#66d9ef>WITH</span> nodesync <span style=color:#f92672>=</span> <span style=color:#960050;background-color:#1e0010>{</span><span style=color:#e6db74>&#39;enabled&#39;</span>: <span style=color:#e6db74>&#39;true&#39;</span><span style=color:#960050;background-color:#1e0010>}</span>;
</code></pre></div><p>Save Points:</p><ul><li>each node splits its local range into segments<ul><li>small token range of a table</li></ul></li><li>each segment makes a save point<ul><li>NodeSync repairs a segment</li><li>then NodeSync saves its progress</li><li>repeat</li></ul></li><li>NodeSync priorities segments to meet the deadline target</li></ul><p>Segments sizes:</p><ul><li>determining token range in a given segment is a simple recursive split</li><li>target is each segment is less than 200MB<ul><li>configurable, but good default, <em>segment_size_target_bytes</em></li><li>greater than a partition</li><li>so partitions greater than 200MB win over segments less than 200MB</li></ul></li><li>algorithm doesn&rsquo;t calculate data size but instead assumes acceptable distribution of data among your cluster</li></ul><p>Segment failures</p><ul><li>nodes validate/repair segments as a whole</li><li>if node fails during segment validation, node drops all work for that segment and starts over</li><li>node records successful segment validation in the <em>system_distributed.nodesync_status</em> table</li></ul><p>Segment outcomes</p><ul><li>full_in_sync: all replicas ware in sync</li><li>full_repaired: some repair necessary</li><li>partial_in_sync: not all replicas responded (at lest 2 did), but all respondent ware in sync</li><li>partial_repaired: not all replicas responded (at least 2 did), with some repair needed</li><li>uncompleted: one node available/responded; no validation occured</li><li>failed: inexpected error happend; check logs</li></ul><p>Segment validation:</p><ul><li>NodeSync simply performs a read repair on the segment</li><li>read data from all replicas</li><li>check for inconsistencies</li><li>repair stale nodes</li></ul><h2 id=write-path>Write path
<a class=anchor href=#write-path>#</a></h2><p>Writes:</p><ul><li>MemTable (in RAM)<ul><li>always ordered by partition key and clustering column</li></ul></li><li>Commit Log (on disk)<ul><li>stored sequentially, every record just append to the commit log</li></ul></li><li>After the data stored into MemTable and Commit log, Cassandra sends acknowledge to the client</li><li>When MemTAble is full, it flushes to the disk and this structure called <em>SSTable</em> (and now this structure is immutable)</li><li>After that, Cassandra deletes Commit log, because it already has sorted data on the disk</li></ul><p>It&rsquo;s recommended to store Commit Log on different storage as SSTables</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># run stress test</span>
cassandra-stress write no-warmup n<span style=color:#f92672>=</span><span style=color:#ae81ff>250000</span> -port native<span style=color:#f92672>=</span><span style=color:#ae81ff>9041</span> -rate threads<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
<span style=color:#75715e># show data of the stress test</span>
nodetool cfstats keyspace1.standard1
</code></pre></div><h2 id=read-path>Read path
<a class=anchor href=#read-path>#</a></h2><p>Reads:</p><ul><li>from MemTable:<ul><li>just find value in MemTable with binary search</li></ul></li><li>from SSTAble:<ul><li>SSTAble file has an index file, which stores partition token and its offset in bytes</li><li>Partition summary - im memory index of partition indexes</li><li>result of read is stored in key cache for case if client want to read similar data next time</li></ul></li></ul><h3 id=bloom-filter>Bloom filter
<a class=anchor href=#bloom-filter>#</a></h3><p>need to google it !!1!</p><h3 id=dse-read-path-optimizations>DSE Read Path Optimizations
<a class=anchor href=#dse-read-path-optimizations>#</a></h3><ul><li>no partition summary</li><li>partition index changed to a trie-based data structure</li><li>SSTable lookups in this format scream!</li><li>huge performance improvements; especially for the large SSTables</li></ul><h2 id=compactions>Compactions
<a class=anchor href=#compactions>#</a></h2><p>Compaction is a process of merging few SSTables into one SSTable.</p><p>During compaction Cassandra selected more recent data (with greater timestamps)
When you delete data? Cassandra actually writes a tombstone instead deleted record,
so during compaction if this record timestamp is greater than 10 days (by default, configurable in <em>cassandra.yaml</em>),
it will skipped, in other case it will write to result file.</p><h3 id=compaction-strategies>Compaction strategies
<a class=anchor href=#compaction-strategies>#</a></h3><ul><li>Compaction strategies are configurable. These strategies include:<ul><li>Size Tiered Compaction (default) - triggers when multiple SSTables of a similar size are present</li><li>Leveled Compaction - groups SSTables into levels, each of which has a fixed size limit
which is 10 times larger than the previous level</li><li>TimeWindow Compaction - creates time windowed buckets of SSTables that are compacted with each other
using the Size Tiered Compaction Strategy</li></ul></li><li>Use the <em>ALTER TABLE</em> command to change the strategy</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#66d9ef>ALTER</span> <span style=color:#66d9ef>TABLE</span> myKeySpace.myTable
<span style=color:#66d9ef>WITH</span> compaction <span style=color:#f92672>=</span> <span style=color:#960050;background-color:#1e0010>{</span><span style=color:#e6db74>&#39;class&#39;</span>: <span style=color:#e6db74>&#39;LeveledCompactionStrategy&#39;</span><span style=color:#960050;background-color:#1e0010>}</span>;
</code></pre></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#cql-fundamentals>CQL Fundamentals</a><ul><li><a href=#core-datatypes>Core datatypes</a></li></ul></li><li><a href=#partitions>Partitions</a></li><li><a href=#clustering-columns>Clustering columns</a><ul><li><a href=#changing-default-ordering>Changing default ordering</a></li></ul></li><li><a href=#node>Node</a><ul><li><a href=#nodetool>Nodetool</a></li></ul></li><li><a href=#ring>Ring</a><ul><li><a href=#joining-the-cluster>Joining the Cluster</a></li><li><a href=#drivers>Drivers</a></li></ul></li><li><a href=#vnodes>Vnodes</a></li><li><a href=#gossip>Gossip</a></li><li><a href=#snitch>Snitch</a><ul><li><a href=#configuring-snitches>Configuring snitches</a></li></ul></li><li><a href=#replication>Replication</a></li><li><a href=#consistency>Consistency</a></li><li><a href=#hinted-handoff>Hinted handoff</a></li><li><a href=#read-repair>Read repair</a><ul><li><a href=#nodetool-repair>Nodetool repair</a></li></ul></li><li><a href=#node-sync>Node sync</a></li><li><a href=#write-path>Write path</a></li><li><a href=#read-path>Read path</a><ul><li><a href=#bloom-filter>Bloom filter</a></li><li><a href=#dse-read-path-optimizations>DSE Read Path Optimizations</a></li></ul></li><li><a href=#compactions>Compactions</a><ul><li><a href=#compaction-strategies>Compaction strategies</a></li></ul></li></ul></nav></aside></main></body></html>