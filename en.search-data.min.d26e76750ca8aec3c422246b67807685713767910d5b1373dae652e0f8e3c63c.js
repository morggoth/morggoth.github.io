'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/mooc/math/sets/','title':"Теория множеств",'section':"Книга для чтения по высшей математике",'content':"Теория множеств #  Основные понятия #  Множество - совокупность элементов, объединенных по какому-либо признаку.\nМножества:\n конечные бесконечные  Обозначения:\n  \\(x \\in X - x \\text{ является элементом множества } Х \\\\ x \\forall - \\text{ для всех } x \\\\ x \\exists - \\text{ существует } x \\\\ \\alpha \\implies \\beta - \\text{ следовательно(импликация) } \\\\ \\alpha \\iff \\beta - \\text{ эквивалентно } \\\\ U - \\text{ универсум } \\\\\\)  Универсум (универсальное множество) - разумное множество элементов, за пределы которого не выходят при рассмотрении больших множеств.\nПодмножества #  Обозначается:  \\(A \\subset B - \\text{ (теоретико-множественное) включение }\\)  Определение:  \\(x \\in A \\implies x \\in B\\)  Т.е. A есть часть B.\n \\(A = B \\text{ if } A \\subset B \\text{ and } B \\subset A\\)  Т.e. множества A и B состоят из одних и тех же элементов.\nОперации над множествами #   Объединение(\u0026ldquo;ИЛИ\u0026rdquo;)  \\(A \\cup B\\)   Пересечение(\u0026ldquo;И\u0026rdquo;)  \\(A \\cap B\\)   Дополнение (\u0026ldquo;НЕ\u0026rdquo;; множество всех элементов U, не входящих в А)  \\(\\overline{A}\\)    Пустое множество #   \\(\\varnothing\\)  Не имеет ни одного элемента. Таким образом, пересечение непересекающихся множеств даёт:\n \\(A \\cap B = \\varnothing\\)  Основные свойства:  \\(A \\cup \\varnothing = A \\\\ A \\cap \\varnothing = \\varnothing \\\\ A \\cap \\overline{A} = \\varnothing\\\\ \\overline{\\varnothing} = U \\\\ \\varnothing = \\overline{U} \\\\\\)  Производные свойства множеств #   \\(A \\cup B = B \\cup A \\\\ A \\cup A = A \\\\ A \\cap B = B \\cap A \\\\ A \\cap A = A \\\\ A \\cup \\overline{A} = U \\\\ \\overline{\\overline{A}} = A \\\\ A \\cup ( B \\cup C ) = ( A \\cup B ) \\cup C \\\\ A \\cap ( B \\cap C ) = ( A \\cap B ) \\cap C \\\\ A \\cap ( B \\cup C ) = ( A \\cap B ) \\cup ( A \\cap C ) \\\\ A \\cup ( B \\cap C ) = ( A \\cup B ) \\cap ( A \\cup C ) \\\\\\)  Объединение и пересечение произвольного числа множеств  \\(A_1, A_2, ..., A_m\\)  обозначается:\n \\(\\bigcup_{i=m}^m A_i \\Big( \\bigcap_{i=m}^m A_i\\Big)\\)  Формулы Де Моргана #   \\(\\overline{A \\cup B} = \\overline{A} \\cap \\overline{B} \\\\ \\overline{A \\cap B} = \\overline{A} \\cup \\overline{B}\\)  Теория бесконечных множеств #  Пусть  \\(f : X \\to Y\\)  т.е. f - отображение (\u0026ldquo;функция\u0026rdquo;), у которой множеством задания является Х, на множество значений лежит в Y. Тогда каждому:\n \\(x \\in X\\)  сопоставляется элемент  \\(y = f(x) \\in Y\\)  Отображение такого вида называется взаимно однозначным соответствием, если для каждого  \\(y \\in Y\\)  существует единственный элемент  \\(x \\in X\\)  такой, что  \\(f(x) = y\\)  Если для множеств X и Y существует взаимно однозначное соответствие, то эти множества называются эквивалентными или равномощными. Обозначается  \\(X \\sim Y\\)  Свойства эквивалентности:  \\(X \\sim X \\\\ X \\sim Y \\implies Y \\sim X \\\\ X \\sim Y, Y \\sim Z \\implies X \\sim Z\\)  Мощность множества А - класс всех эквивалентных ему множеств. Соответственно, мощности множеств равны тогда и только тогда, когда они эквивалентны.\nИзначально мощность множества выражалась через количество его элементов.\nМножество, эквивалентное натуральному ряду называется счетным, не эквивалентное - несчетным.\nМощности четных(и нечетных), натуральных, целых и рациональных чисел равны. Кроме того, они равны и мощностям плоскости и трёхмерного пространства.\nМощность числовой прямой также носит название континуум.\nТеория конечных множеств #  Является частью дискретной математики.\nКомбинаторика - раздел математики, посвященный решению задач выбора и расположения элементов некоторого, обычно конечного множества в соответствии с заданными правилами.\nЕсли мы имеем дело с непустым конечным множеством M, состоящим из m элементов, это обозначается как:\n \\(|M| = m\\)  Отличие от обозначения модуля числа определяется только по контексту.\nРазмещение из m элементов по n - упорядоченный набор, составленный из n различных элементов множества M.  \\(1 \\le n \\le m\\)  Обозначается:  \\(A^n_m = \\frac{m!}{(m-n)!}\\)  Перестановкой называют размещение из m элементов по m.\n \\(P_m = m!\\)  Сочетанием из m элементов по n называется набор, состоящий из n различных элементов множества M.\n \\(C^n_m = \\frac{A^n_m}{P_m} = \\frac{m!}{(m-n)n!}\\)  Сочетание может быть использовано, например, для определения коэффициентов многочлена  \\((1 \u0026#43; x)^m\\)  при некотором фиксированном m:\n \\((1\u0026#43;x)^m = C_m^0 \u0026#43; C_m^1x \u0026#43; C_m^2x^2\u0026#43;...\u0026#43;C_m^mx^m = \\sum_{n=0}^m C_m^nx^n\\)  Эта формула называется биномом Ньютона, а сочетания в ней - биноминальными коэффициентами. Их сумма:  \\(\\sum_{n=0}^m C^n_m = 2^m\\)  "});index.add({'id':1,'href':'/docs/mooc/math/numbers/','title':"Числа",'section':"Книга для чтения по высшей математике",'content':"Числа #  Появление чисел #  Натуральное число в десятичной записи имеет вид:   \\(n = \\sum_{m=0}^{k-1} a_m 10^m \\\\ 0 \\le a-m \\le 9 \\text{, } m = 0, 1,...,k-1\\)  Расширяя эту формулу можно записать, что любое натуральное число  \\(n \\in \\N\\)  может быть представлено в виде:  \\(n = \\sum_{m=0}^{k-1} b_mp^m \\\\ 0 \\le b_m \\le p-1, m = 0, 1,..., k-1\\)  Это число записывается в p-ричной системе счисления, имеющей p цифр.\n9376 - единственное четырехзначное число, у которого при возведении в квадрат сохраняются последние 4 цифры: 9376^2 = 87909376  Целые числа(расширение натуральных чисел отрицательными и нулём):\n \\(x \u0026#43; q = p \\\\ p, q \\in \\N\\)  Рациональные числа(расширение целых чисел дробями):\n \\(qx = p \\\\ p,q \\in \\Z, q \\ne 0\\)  Вещественные числа(расширяют рациональные иррациональными; возникли из необходимости измерения непрерывных величин)\nТеорема: корень квадратный из 2 - иррациональное число #  Доказательство от противного. Предположим, что это рациональное число, тогда:  \\(\\sqrt 2 = \\frac{p}{q} \\\\ p,q \\in \\N\\)  p и q - взаимно простые числа(то есть не имеют общих делителей, кроме 1) =\u0026gt; по крайней мере одно из них - нечетное. Возводя обе части равенства в квадрат, получаем:  \\(p^2 = 2q^2\\)  Откуда следует, что p - четное число, таким образом,  \\(p = 2m \\\\ m \\in \\N\\)  Подставляя это выражение вместо p в предыдущее равенство, получаем:  \\(4m^2 = 2q^2 \\implies 2m^2 = q^2\\)  откуда следует, что и q - четное, что является противоречием.\nТеория чисел #  Теория чисел - раздел математики, изучающий целые числа.\nТеория простых чисел - натуральное число p \u0026gt; 1 называется простым, если оно делится только на единицу и на само себя. Натуральное число q \u0026gt; 1, не являющееся простым, называется составным.\nТеорема Евклида: Множество простых чисел бесконечно.\nДоказательство. Предположим обратное. Тогда:  \\(n_1 \u0026lt; n_2 \u0026lt; ... \u0026lt; n_m\\)  все простые числа. Составим число:  \\(p = n_1n_2...n_m \u0026#43; 1\\)  Так как p - больше наибольшего простого числа, оно составное. Но в этом случае, оно должно делиться на одно из простых чисел, однако из вида этого числа следует, что при делении его на любое простое число получится остаток 1, что и является искомым противоречием.\nЕвклидом же был введено понятие чисел-близнецов. Это такие простые числа:  \\(p, q, \\text{ } p \u0026gt; q \\\\ p - q = 2\\)  Он же поставил вопрос, является ли множество чисел близнецов бесконечным? Этот вопрос до сих пор не имеет ответа.\nТреугольник со сторонами 3,4,5 - называется египетский.  Теорема Ферма: Не существует натуральных чисел x, y, z, удовлетворяющих уравнению  \\(x^n \u0026#43; y^n = z^n \\\\ n \\ge 3\\)  "});index.add({'id':2,'href':'/docs/mooc/math/complex_numbers/','title':"Комплексные числа",'section':"Книга для чтения по высшей математике",'content':"Комплексные числа #  Появились в XVIв. в процессе исследования алгебраических уравнений(квадратных, кубических и т.д.). Как известно из школьного курса алгебры, некоторые такие уравнения \u0026ldquo;не имеют корней\u0026rdquo;. Но это верно только на множестве вещественных чисел. Для решения этой проблемы множество вещественных чисел было расширено так, чтобы подобные корни появились. Другое название комплексных чисел - мнимые.\nПо определению комплексно число - это упорядоченная пара вещественных чисел, обозначаемая (a, b). Эти числа можно интерпретировать как координаты точки(a - абсцисса, b - ордината).\nАбсцисса - координата точки по оси X\nОрдината - \u0026ndash;\\\u0026ndash; Y\nАппликата - \u0026ndash;\\\u0026ndash; Z  Два комплексных числа (a, b) и (c, d) считаются равными тогда и только тогда, когда:   \\(a = c \\\\ b = d\\)  Сложение комплексных чисел:  \\((a, b) \u0026#43; (c, d) = (a\u0026#43;c, b\u0026#43;d)\\)  Умножение:  \\((a, b)(c, d) = (ac - bd, ad \u0026#43; bc)\\)  Таким образом, произведение не зависит от порядка сомножителей.\nВычитание - нахождение неизвестного слагаемого\nДеление - нахождение неизвестного сомножителя   \\((a, b) - (c, d) = (a-c, b-d) \\\\ \\\\ \\dfrac{(a,b)}{(c,d)} = \\Big( \\dfrac{ac\u0026#43;bd}{c^2\u0026#43;d^2}, \\dfrac{bc-ad}{c^2\u0026#43;d^2} \\Big) \\text{ ,где}\\\\ (c,d) \\ne (0,0)\\)  Рассмотрим точки, лежащие на оси абсцисс, например (a, 0). Для таких комплексных чисел операции сложения и умножения дают следующие результаты:  \\((a,0) \u0026#43; (b,0) = (a\u0026#43;b,0) \\\\ (a,0)(b,0) = (ab, 0)\\)  из которых видно, что алгебра комплексных чисел, лежащих на лси абсцисс совпадает с алгеброй вещественных чисел, таким образом:  \\((a,0) = a\\)  Все вещественные числа (и только они) лежат на оси абсцисс, которая так же является числовой прямой. А все точки с ненулевой ординатой являются невещественными числами.\nДокажем, что в множестве комплексных чисел существует корень уравнения:  \\(x^2 \u0026#43; 1 = 0\\)  то есть, существует число, квадрат которого равен -1. Для этого возведем в квадрат число (0, 1):  \\((0,1)(0,1) = (-1,0) = -1\\)  Комплексное число (0,1), называемое мнимой единицей, Л. Эйлер предложил обозначать буквой i:  \\(i^2 = -1\\)  Таким образом, точкам оси ординат отвечают комплексные числа вида bi, где b - произвольное вещественное число.\nОбычно комплексные числа записывают в виде:  \\(a \u0026#43; bi\\)  Такая запись использует декартовы координаты точки. Кроме того, существует тригонометрическая форма записи комплексного числа. Положение точки на плоскости может быть определено с помощью расстояния от этой точки до начала координат и угла между положительным направлением оси абсцисс и лучом, выходящим из начала координат и проходящим через эту точку.\nДля комплексного числа a+bi упомянутые величины обозначаются через:  \\(r \\text{ - расстояние} \\\\ \\varphi \\text{ - угол}\\)  Таким образом, при любом расположении точки a + bi на координатной плоскости справедливы соотношения:  \\(x = r \\cos \\varphi, \\\\ y = r \\sin \\varphi\\)  Отсюда, а так же из теоремы Пифагора следует:  \\(r = \\sqrt{a^2 \u0026#43; b^2}\\)  Число r называется модулем комплексного числа a + bi, а угол - аргументом. При r = 0 модуль не определен. Единственное число с нулевым модулем - (0,0)\nК комплексным числам не применимы неравенства типа \u0026ldquo;больше\u0026rdquo; или \u0026ldquo;меньше\u0026rdquo;, поэтому сравнивать их можно только по модулю.\nОсновная теорема алгебры #  Пусть  \\(P(z) = a_0 \u0026#43; a_1 z \u0026#43; a_2 z^2 \u0026#43; ... \u0026#43; a_n z^n -\\)  многочлен(полином) с комплексными коэффициентами  \\(a_0, a_1, a_2,...,a_n\\)  заданный в комплексной плоскости, т.е. множестве чисел z = a + bi. Если  \\(a_n \\ne 0\\)  то говорят, что многочлен P имеет степень n.\nОсновная теорема алгебры: Если степень многочлена n \u0026gt;= 1, то уравнение  \\(P(z) = 0\\)  имеет, по крайней мере один комплексный корень.\nЭто утверждение также называется Теоремой Гауса.\nОсновным следствием этой теоремы является то, что любой многочлен степени n \u0026gt;= 1 может иметь не более n корней (при этом некоторые из них могут совпадать).\nСтоит отметить, что общей формулы для уравнений степени n \u0026gt;= 5 не существует.\n"});index.add({'id':3,'href':'/docs/mooc/math/matrices/','title':"Матрицы",'section':"Книга для чтения по высшей математике",'content':"Матрицы #  Матрицами в математике называется прямоугольная таблица чисел:   \\(\\begin{pmatrix} a_11 \u0026amp; a_12 \u0026amp; ... \u0026amp; a_1m \\\\ a_21 \u0026amp; a_22 \u0026amp; ... * a_2m \\\\ ... \u0026amp; ... \u0026amp; ... \u0026amp; ... \\\\ a_n1 \u0026amp; a_n2 \u0026amp; ... \u0026amp; a_nm \\end{pmatrix}\\)  Сами числа в этом случае называются элементами матрицы. Эту же матрицу для упрощения обозначают:  \\(\\Vert a_{ij} \\Vert\\)  Имея в виду, что i принимает значения от 1,\u0026hellip;,m, а j, соответственно, 1,\u0026hellip;,n. Если m = n, матрица называется квадратной, а число m=n ее порядком. Прямоугольная матрица, в которой n=1, называется столбцом. Квадратная матрица порядка 1 отождествляется с числом, поэтому понятие матрицы можно считать обобщением понятия числа.\n(0,1)-матрица - такая матрица, все элементы которой равны либо 0, либо 1. Наиболее известные подобные матрицы:\n O - нулевая матрица, то есть матрица, все элементы которой равны 0 E - единичная матрица, то есть квадратная матрица, в которой все \u0026ldquo;диагональные\u0026rdquo; элементы равны 1, а остальные - 0  Алгебра произвольных квадратных матриц #  Пусть  \\(A = \\Vert a_{ij} \\Vert , B = \\Vert b_{ij} \\Vert\\)  квадратные матрицы порядка n. Матрицы A и B считаются равными, если  \\(a_{ij} = b_{ij}\\)  для всех возможных i и j.\nСуммой A + B матриц A и B называется такая матрица C, элементы, которой равны сумме элементов исходных матриц, то есть матрицы складываются \u0026ldquo;поэлементно\u0026rdquo;.\n"});index.add({'id':4,'href':'/docs/misc/cheatsheets/','title':"Cheatsheets",'section':"Docs",'content':"SQL   SELinux commands   Tools   Network   Linux permissions   x64 CPU   AWS   "});index.add({'id':6,'href':'/docs/misc/rpi/','title':"Raspberry Pi",'section':"Docs",'content':"Install CentOS 7 #  # Download an image wget -O centos7-aarch64.raw.xz http://mirrors.powernet.com.ru/centos-altarch/7/isos/aarch64/images/CentOS-Userland-7-aarch64-RaspberryPI-Minimal-4-2009-sda.raw.xz # List available devices diskutil list # Unmount sdcard diskutil unmountDisk /dev/diskN # Flash the image and flush write cache xzcat centos7-aarch64.raw.xz| sudo dd bs=1m of=/dev/rdiskN; sync # Eject sdcard sudo diskutil eject /dev/rdiskN # Resize root partition rootfs-expand Install k8s via kubeadm #  If you are faced into:\n[ERROR SystemVerification]: missing required cgroups: memory  you have to enable memory cgroups by adding cgroup_enable=memory to the /boot/cmdline.txt. Of course you must restart your machine.\n"});index.add({'id':7,'href':'/docs/k8s/','title':"Kubernetes",'section':"Docs",'content':"TODO:\n https://github.com/ContainerSolutions/k8s-deployment-strategies https://www.freecodecamp.org/news/the-kubernetes-handbook/ https://monicabhartiya.com/posts/kubernetes-syllabus-update https://github.com/kelseyhightower/kubernetes-the-hard-way https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-b190cc97f0f6  "});index.add({'id':8,'href':'/docs/k8s/k8s/','title':"Operator intro",'section':"Kubernetes",'content':"Оператор #  Доклад\n сущность, управляющая другими сущностями в кластере содержит шаблоны поведения основные задачи:  облегчение жизни операторов k8s уменьшение количества микроменеджмента (автоматизация типовых задач по обслуживанию кластера)    Оператор обслуживает весь жизненный цикл (например масштабирование, шардирование и т.д.; в отличии от Helm, который только ставит пакеты)\nПри построении оператора исходить из того, что он будет управлять необходимой сущностью как одним ресурсом (в качестве примера, оператор для кластера CH, который воспринимает его как одну сущность)\nМанифест для однонодной инсталяции CH:\napiVersion: \u0026#34;clickhouse.altinity.com/v1\u0026#34; # NB - apiVersion ссылается на другой URL kind: \u0026#34;ClickHouseInstallation\u0026#34; # NB - кастомная сущность metadata: name: \u0026#34;demo-01\u0026#34; spec: configuration: clusters: - name: \u0026#34;demo Persistent storage #  Local storages:\n emptyDir  доступ к каталогу на хост-машине через демон контейнеризации работает со скоростью доступа к локальному диску данные приколочены к ноде, при перемещении пода, данные теряются   hostPath  использование конкретного каталога на хостовой машине при перемещении на другую ноду данные не переносятся   local  все то же самое, но локальный каталог управляется самим k8s    Взаимодействие оператора с k8s #  kubectl apply -\u0026gt; новые объекты -\u0026gt; API -\u0026gt; Etcd\nController - сущность, которая реализует изменения в наборе объектов, которые были записаны в Etcd.\nCustom Resource Definition - описание \u0026ldquo;структуры данных\u0026rdquo;\nOperator (Custom Resource Controller) - контроллер, который может создать кастомный ресурс. До его появления в кластере, даже если кастомный ресурс будет добавлен в Etcd, ничего не произойдет, потому что дефолтный контроллер не знает что с ним делать.\nОператор может исполняться снаружи кластера.\nЦикл обработки событий оператором #   с помощью K8s API подписывается на те или иные события при наступлении события, реагирует на него тем или иным образом  составление плана действий исполнение поставленного плана    Разделение ответственности между k8s и оператором #  k8s - отвечает за системные ресурсы, базовый набор объектов Оператор - действует только в своей предметной области\nЕсли на момент наступления события, оператор не мог его обработать, k8s продублирует отправку этого события (то есть, видимо, должна быть обратная связь). Т.о., задача оператора, в том числе, обеспечение идемпотентности.\nJobs \u0026amp; CronJobs #  Вспомним, как в Kubernetes реализована концепция остановки подов. Когда приходит время остановить под, то есть все контейнеры в поде, контейнерам посылается sigterm-сигнал и Kubernetes ждёт определённое время, чтобы приложение внутри контейнера отреагировало на этот сигнал.\nВ нашем случае приложение — это простой bash-скрипт с бесконечным циклом, реагировать на сигнал некому. Kubernetes ждёт время, которое задано в параметре graceful shutdown. По дефолту — 30 секунд. То есть если за 30 секунд приложение на sigterm не среагировало, дальше посылается sigkill и процесс с pid 1 внутри контейнера убивается, контейнер останавливается. Поле restartPolicy\nПри проверке backoffLimit поды у нас перезагружались. При этом в манифесте указан параметр restartPolicy: Never. Но когда мы смотрели, как работает опция backoffLimit, поды перезагружались. Здесь нет противоречия: если вы посмотрите на весь yaml-файл, то заметите, что этот параметр относится не к Job, а к спецификации контейнера, который запускается внутри пода.\napiVersion: batch/v1 kind: Job metadata: name: hello spec: backoffLimit: 2 activeDeadlineSeconds: 60 template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: Never Этот параметр говорит kubelet, что делать с контейнером после того, как он был завершён с ошибкой. По умолчанию стоит политика Always, то есть если у нас контейнер в поде завершился, kubelet этот контейнер перезапускает. Причем, все остальные контейнеры в поде продолжают работать, а перезапускается только упавший контейнер.\nЭто политика по умолчанию, и если её применить в Job, то Job-контроллер не сможет получить информацию о том, что под был завершён с ошибкой. С его точки зрения под будет очень долго выполняться, а то, что kubelet перезапускает упавший контейнер, Job-контроллер не увидит.\nЕсли вы укажете только backoffLimit, но забудете указать restartPolicy, то Job будет выполняться бесконечно. Поэтому в Job надо всегда указывать: backoffLimit (количество попыток), activeDeadlineSeconds (общее время), restartPolicy: Never (сказать kubelet, чтобы он никогда не перезапускал контейнер в поде; если контейнер в поде упал, то и сам под считается упавшим, то есть завершённым. Пусть Job-контроллер разбирается, что произошло).\n"});index.add({'id':9,'href':'/docs/misc/kafka/','title':"Kafka basics",'section':"Docs",'content':"Kafka cluster #   broker  отвечает за хранение данных (в бинарном виде) не знаком со внутренней структурой хранимых данных топик - сущность для логического разделения хранимых данных:  на уровне топика можно задать ограничения на:  объём и/или возраст хранимых данных (retention.bytes, retention.ms) количество реплик данных (replication factor) максимальный размер одного сообщения (max.message.bytes) минимальное число согласованных реплик, при котором можно будет записать данные (min.insync.replicas) и многое другое   разбивается на партиции - сущность, непосредственно содержащая сообщения  распределяются по брокерам равномерно (насколько это возможно), что позволяет масштабировать нагрузку на RW в один топик на диске хранится в виде файлов-сегментов с дефолтным размером в 1GB (log.segment.bytes) данные из партиции можно удалить только целым сегментом (не активным) распределение событий (сообщений) по партициям:  нет ключа - round robin (с потерей упорядоченности) есть ключ - murmurHash(key) (с сохранением упорядоченности)   в рамках одной партиции может быть гарантирован порядок событий       zookeeper  роли:  хранилище метаданных координатор кластера   в том числе хранит информацию о:  состоянии брокеров том, какой брокер является контроллером синхронизированы ли партиции с репликами распределении топиков и партиций по брокерам если replication factor \u0026gt; 1:  какая партиция лидер (именно в нее будет идти RW)     в старых версиях также хранил оффсеты (сейчас перенесены в топик __consumer_offsets) при потере, данные с большой долей вероятности превратятся в фарш   producer  сервис, который непосредственно пишет данные в Kafka отправляет KV-сообщения в выбранный топик   consumer  получает данные из Kafka offset - номер последнего сообщения, полученного конкретным подписчиком consumer group - логическое объединение подписчиков, в котором читаемые данные распределяются между участниками группы; позволяет масштабировать скорость чтения    "});index.add({'id':10,'href':'/docs/mooc/','title':"Courses notes",'section':"Docs",'content':"Courses notes #  "});index.add({'id':11,'href':'/docs/mooc/datastax_academy/cassandra_operations/','title':"DS210: DataStax Enterprise 6 Operations with Apache Cassandra™",'section':"Courses notes",'content':"Configuring clusters: YAML #  cassandra.yaml - the main configuration file\n Cassandra nodes read this file on start-up  restart of the node if needed for the changes to take effect   Located in the following directories:  cassandra package installations: /etc/dse/cassandra cassandra tarball installations: ${install_root}/resources/cassandra/conf    Minimal properties #   cluster_name listen_address native_transport_address (ip address, which use by the clients to connect to the node) seeds  Commonly user YAML settings #    endpoint_snitch\n  initial_token / num_token\n  commitlog_directory\n  data_file_directories\n  hints_directory\n  saved_caches_directory\n  hinted_handoff_enabled\n  max_hint_windows_in_ms\n  row_cache_size_in_mb\n  file_cache_size_in_mb\n  memtable_heap_space_in_mb/memtable_offheap_space_in_mb\n  Cluster sizing #   estimates are only a rough-order of magnituge dua to metadata things to consider when estimating cluster size:  throughput - how much data per second? growth rate - how fast does capacity increase? latency - how quickly must the cluster respond?    Throughput:\n measure throughput in data movement per time period (e.g. GB/S) consider reading and writing separately a function of:  operation generators (e.g. users) rate of operation generations (e.g. 3 clicks per minute) size of the operations (number of rows X row width) operation mix (read/write ratio)    Growth rate:\n how big must the cluster be just to hold the data? given the write throughput, we can calculate growth  what is the new/update ratio? what is the replication factor? additional headroom for operations    Latency:\n calculating cluster capacity is not enough understand you SALs  in terms of latency in terms of throughput   relevant factors:  IO rate workload shape access patterns table width node profile (i.e. cores, memory, storage, network)   improve estimates with benchmarking  Cassandra stress #  cassandra-stress = utility fir benchmarking/load testing a cluster\n simulates a user-defined workload use the cassandra-stress to:  determine schema performance understand how your database scales optimize your data model and settings determine production capacity   try out your database berore you go into production  You can configure cassandra-stress with yaml file:\n define your schema specify any compaction strategy create a characteristic workload without writing a custom tool  config sections:\n schema description  defines the keyspace and table information if the schema is not yet defined the test will create it if the schema already exists, only defines the keyspace and table names   column description  describes how to generate the data for each column the data values are meaningless, but simulate the patterns in terms of size and frequency generated values follow a specified distribution such as Uniform, Exponential, Gaussian parameters include:  data size value population cluster distribution (the number of values for the column appearing in a single partition (cluster columns only))  EXP(min\u0026hellip;max) - an exponential distribution over tha range EXTREME(min\u0026hellip;max, shape) - an extreme value distribution over the range GAUSSIAN(min\u0026hellip;max, stdvrng) - a gaussian/normal distribution, where mean=(min+max)/2 and stdev is (mean-min)/stdvrng GAUSSIAN(min\u0026hellip;max, mean, stdev) - a gaussian/normal distribution. with explicity defined mean and stdev UNIFORM(min\u0026hellip;max) - a uniform distribution over the range FIXED(val) - a fixed distribution, always returning the same value       batch description  specifies how the test inserts data for each insert operation, specifies the following distributions/ratios:  partition distribution - number of partitions to update per batch (default FIXED(1)) select distribution ratio - portion of rows from a partition included in particular batch (default FIXED(1)/1) batch type - the type if CQL batch to use; either LOGDEG/UNLOGDEG (default LOGDEG)     query description  you can specify any CQL query on the table by naming them under the queries section fields specifies if the bind variables should be from the same row or across all rows in the partition    Nodetool for performance analysis #  nodetool sub-commands:\n info compactionhistory gcstats (gets Java\u0026rsquo;s GC statistics) gossipinfo ring (gets info about tokens range assignments) tablestats teblehistograms tpstats  Low GC times are desirable so Cassandra can spend more time servicing requests.\nSystem and output logs #   by default. the log file is in /var/log/cassandra/system.log also check debug.log in the same directory system.log logs INFO messages and above debug.log logs all messages change the location by adding the following line to /etc/dse/cassandra/jvm.options:  -Dcassandra.logdir=${PATH_TO_NEW_LOG_DIR} Logging levels:\n OFF ERROR WARN INFO (default) DEBUG TRACE ALL  Logging configuration:\n logback.xml (in the same directory as cassandra.yaml) nodetool setlogginglevel - sets log level for particular Java class, until node restart  nodetool getlogginglevels JVM GC logging #  Turn on GC logging:\n statically by editing jvm.options  -XX:+PrintGC - simple, prints a line for every GC and every full GC -XX:+PrintGCDetails - detailed, young generation as well as old and perm gen -XX:+PrintGCTimeStamps - adds time ti a simple or detailed GC log -XX:+PrintGCDateStamps - adds date to a simple or detailed GC log   dinamically by using jinfo  jinfo -flag +PrintGC ${NODE_PID} jinfo -flag +PrintGCTimeStamps ${NODE_PID} jinfo -flag +PrintGCDateStamps ${NODE_PID}    In either case, edit /etc/dse/cassandra/jvm.options git specify the GC log file:\n-Xloggc:${PATH_TO_GC_LOG_FILE} Adding/removing nodes #   reached data capacity problem  your data has outgrown the node\u0026rsquo;s hardware capacity   reached traffic problem  your application needs more rapid response with less latency   to increase operational headroom  need more resources for node repair, compaction, and other resource intensive operations    Adding nodes, best practices #    Single-Token nodes\n double the size of your cluster    VNodes\n we can add nodes incrementally    adding a single node at a time will:\n result in more data movement will have a gradual impact on cluster performance will take longer to grow cluster    adding multiple nodes at the same time:\n is possible use extreme caution    Bootstrapping #  Bootstrapping is a process of a new node joining a cluster:\n the joining node contacts a seed node the seed node communicates cluster info, including token ranges, to the joining node cluster nodes prepare to stream necessary SSTables cluster nodes stream SSTables to the joining node (can be time consuming) existing cluster nodes continue to satisfy writes, but also forward write to joining node when streaming is complete, joining node changes to normal state and handles read/write requests  To bootstrap a node:\n set up the node\u0026rsquo;s configuration files (cassandra.yaml, etc.)  four main parameters:  cluster_name native_transport_address listen_address -seeds   start up the node normally    Seed node is a just one of the cluster\u0026rsquo;s node.\nWhen bootstrapping fails, we have two scenarios:\n bootstrapping node could not connect to cluster  examine the log file to understand what\u0026rsquo;s going on change config and try again   streaming portion fails  node exists in cluster in joining state first, try restarting the node if restarting fails, try deleting data directories and rebooting or, worst case, remove the node from the cluster and try again    Node cleanup\n perform cleanup after a bootstrap on the OTHER nodes reads all SSTables to make sure there is no token out of range for that particular node if the SSTable is not out of range, cleanup just a copy there are options for running these operations is parallel  bin/nodetool cleanup Removing a node #  Other nodes need to pickup the removed-node\u0026rsquo;s data\nThe cluster needs to know the node is gone.\nThree options for dealing with the data:\n redistribute date from the node that is going away  nodetool decomission  need to decrease the size of the cluster the node must still be active decomission will transfer the data from the decomissioned node to other active nodes in the cluster  with VNodes, the rebalance happens automatically with Single-token nodes, you will need to manually rebalance the tiken ranges on the remaining nodes   after running the nodetool decommossion command:  the node is offline the JVM process is still running (use dse cassandra-stop to kill the process) the data is not deleted from the decommissioned node if you want to add the node back to the cluster, delete the data first!!1!  node deleting the data may cause data resurrection issues         redistribute the data from replicas  nodetool removenode  do this if node is offline and never coming back you can run this command only from other node nodetool removenode will:  make the remaining nodes in the cluster aware that the node is gone copy data from online nodes ti the appropriate replicas to satysfy the replication factor       don\u0026rsquo;t redistribute the data, just make the node go away  nodetool assassinate  do this as a last resort if the node is offline and never coming back nodetool assassinate will:  make the remaining nodes in the cluster aware that the node in gone NOT copy any data   you should use nodetool repair of the remaining nodes to fix the data replication      Replacing a down node #  Benefits of replacing a downed node:\n you don\u0026rsquo;t have to move the data twice backup for a node will work for a replaced node, because same tokens are used to bring replaced node into cluster best option is to replace rather than remove and add  Replacing a downed node using nodetool:\n configure a new node fir the cluster normally with one additional step:  in jvm.options add a replace)address JVM option with IP address of the replaced node:    -Dcassandra.replace_address=${DEAD_NODE_IP_ADDRESS}  once you have configured the node, start the node in the cluster monitor the bootstrapping process using nodetool netstats after the new node if bootstrapperd, you need to remove this option from jvm.options manually  What if the dewned node was also a seed node?\n make sure the old IP address does not appear in seeds list in cassandra.yaml also make sure the new IP address is not in the seeds list in cassandra.yaml perform a rolling restart on all nodes se the nodes are aware of the changes to the seeds list start the replacement node using replace_address in the jvm.options file once the replacement bode is fully up:  renove replace_address from jvm.options add the replacement node\u0026rsquo;s IP to the seeds lists in all the nodes' cassandra.yaml    Compaction #  Leveled compaction #    leveled compaction uses a multiplier of 10 per level by default\n  SSTable max size is 160MB (sstable_size_in_mb)\n  SSTable exceed this amount to ensure the last partioion written is complete\n  Leveled compaction is best for read-heavy workload\n occasional writes but high reads    each pertition resides in only one SSTable per level (max)\n  generally reads handled by just a few SSTables\n partitions group together in a handful of levels as they compact down 90% of the data resides in the lowest level (due to 10x rule) unless the lowest level is not yet full    leveled compaction wastes less disk space\n  obsolete records compact out quickly\n a single partition\u0026rsquo;s records group as they compact down updated records merge with older records due to this grouping    Disadvantages:\n IO intensive compacts many mode SSTables at once size tiered compaction compacts mode frequently than size tierd can\u0026rsquo;t ingest data at high insert speeds  Size tiered compaction #  Default compaction type\nSize tiered compaction triggers compaction based on the number of SSTables.\n  groups similarly sized tables together\n  tiers with less than min_threshold (four) SSTables are not considered for compaction\n  the smaller the SSTables, the \u0026ldquo;thinner\u0026rdquo; the distance between min_threshold and max_threshold\n  SSTables qualifying for more than one tier distribute rabdomly amongst buckets\n  buckets with nore than max_threshold SSTables are trimmed to just that many SSTables\n 32 by default coldest SSTables dropped    Size tiered compaction chooses the hottest tier first to compact\n  SSTable hotness determined by number of reads per second per partition key\n  cassandra compacts several tiers concurrently\n  concurrent_compactors\n default to smaller of number of disks or number of cores, with a minimum of 2 and a maximum of 8 per CPU core tables concurrently compacting are not considered for new tiers    Triggering a compaction:\n compaction starts every time a MemTable flushes to as SSTable MemTable too large, commit log too large or manual flush or when the cluster streams SSTable segments to the node  Bootstrap, rebuild, repair   Compaction continues until there are no more tiers with at least min_threshold tables in it  Tombstones\n if no eligible buckets, size tiered compaction compacts a single SSTable this eliminates expired tombstones the number of expired tombstones must be above 20% largest SSTable chosen first table must be at least one day old before considered  tombstome_compaction_interval   compaction ensures that tombstones DO NOT overlap old records in other SSTables  Absorbs high write-heavy workloads ny procrastinating compaction as losg as possible\nOther compaction strategies don\u0026rsquo;t handle ingesting data as well as size tiered\ncompaction_throughput_mb_per_sec controls the compaction IO load on a node\nMajor compaction #   you can issue a major compaction via nodetool compacts all SSTables into a singla SSTable new monolithic SSTable will qualify for the largest tier future updates/deletes will fall into smaller tiers data in laegest tier will become obsolete yet still hog a log of disk space takes a long tine for changes to propagate up to large tier major compactions not recommended  Time window compaction #  Built for time series data\nAn SSTables spanning two windows simply falls into the second window\nGood practice to aim for 50ish max SSTables on disk:\n 20ish for active window 30ish for all past windows combined  for example: one month of data would have window of a day\nTuning:\n expired_sstable_check_frequency_seconds determines how often to check for fully expired (tombstoned) SSTables good to tune when using a TTL  Repair #  This is consistency check across all the node, than examine that all the data is correct.\n Think of repair as synchronizing replicas Repair ensures that all replicas have identical copies of given partition Repair occurs:  if necessaty when detected by reads (e.g. CL=QUORUM) randomly with non-quorum reads (table property read_repair_chance or dclocal_read_repair_chance) manually using nodetool repair    How does repair work?\n nodes build Merkel trees from partitions to represent how current the data value are nodes exchange the Merkel trees nodes compare the Merkel trees to identify specific values that need synchronization nodes exchange data values and update their data  Merkel tree\n a binary tree of hash values the leaves of the tree represent hashes of the values in the partition each tree-nodes is a hash of its children\u0026rsquo;s hash values when tree-nodes hashes are the same, the sub-trees are the same  When to perform a repair:\n if node has been down for a while on a regular basis:  once every gc_grace_seconds mekr sure the repair can complete within the gc_grace_seconds window schedule for lower utilization periods    Is repair a lot of work for the node:\n a full repair can be a lot of work but there are ways to mitigate the work:  primary range repair sub-range repair    Primary range repair:\n the primary range is the set of tokens the node is assigned repairing only the node\u0026rsquo;s primary range will make sure that data is synchorized for that range repairing only the node\u0026rsquo;s primary range will eliminate redundant repairs  Sub-range repair:\n repairs can consume significant resources depending on how much data is under consideration targeting sub-ranges of the table will reduce the amount of work done by a single repair  Nodesync #  DSE 6+ replacement for repair.\nBehaves like continues background repair that delivers:\n low overhead consistent performance easy to use  How to use:\n create a cluster with at least 2 nodes create keyspace with RF \u0026gt;= 2  CREATE KEYSPACE MyKeyspace WITH replication={\u0026#39;class\u0026#39;: \u0026#39;SimpleStrategy\u0026#39;, \u0026#39;replication_factor\u0026#39;: 2};  create table within the keyspace with NodeSync enables  CREATE TABLE MyTable (k int PRIMARY KEY) WITH nodesync={\u0026#39;enabled\u0026#39;: \u0026#39;true\u0026#39;};  NodeSync will now automatically make sure the table data is synchronized  sstabelesplit #  Brakes large SSTable files in a pieces. Before use this tool? you need to stop node.\nMulti DC concepts #   node - the virtual or physical host of a single Cassandra instance rack - a logiacl grouping os physically related nodes DC - a logical grouping of set of racks enables geographically aware read and write request routing each node belongs to one rack in one DC the identity of each node;s rack and DC may be configured in its conf/cassandra-rackdc.properties file  implementing a multi DC cluster:\n use the NetworkTopologyStrategy rather than SimpleStrategy use LOCAL_* consistency level for read/write operations to limit latency specify the snitch  ALTER KEYSPACE MyKeyspace WITH replication={\u0026#39;class\u0026#39;: \u0026#39;NetworkTopologyStrategy\u0026#39;, \u0026#39;DC1\u0026#39;: 1, \u0026#39;DC2\u0026#39;: 2}; nodetool rebuild -- name_of_existing_data_center CQL copy #   cassandra expects every row in the delimited input to contain the same number of columns the number of columns in the delimited input is the same as the number of columns in the Cassandra table empty data for a column is assumed by default NULL value COPY FROM is intended for importing small datasets (a few million rows or less) into Cassandra for impoting larger datasets, use DSBulk  options:\n DELIMITER (default is comma) HEADER (default is false) CHUNKSIZE - set the size of chunks passed to worker process (default value is 1000) SKIPROWS - the number of rows to slip *default value is 0  sstabledump #  dumps the content of the specified SSTable in the JSON format\nyou may wish to flush the table to the disk before dumping its contests\nsstableloader #  provides the ability to:\n bulk load external data into a cluster load pre-existing cluster or new cluster a cluster with the same number of nodes or a different number of nodes a cluster with different replication strategy or partitioner  it doesn\u0026rsquo;t simply copy the set of SSTables to every node, but transfers the relevant parts of the data to each node confirming of the replication strategy of the cluster.\nDSE DsBulk #  Moves Cassandra data to/from files in the file system\nUses both CSV or JSON formats\nBackup #  Cassandra uses spanshots fir backup data, because:\n  they don;n copy out all the data from DB\n  it\u0026rsquo;s a distributed system; every node has only a portion of the data\n  SSTables are immutable, which makes them easy to back up\n  snapshot create hadrlinks on the file system as opposed to coping data\n this is different than coping actual data files (takes less disk space)    therefile very fast\n  represents the state of the data files at a particular point in the time\n  can consist of a single table, single keyspace ot multiple keyspace\n  incremental backup:\n create a hard link to every SSTable upon flush  user must manually delete them after creating a new shapshot   incremental backups are disabled by default (cassandra.yaml, incremetal_backups: true) need a snapshot before taking inkremental backup snapshot information is stored in a snapshots directory under each table directory  backups storred per node and contains only data from this node.\nnodetool snapshot nodetool clearsnapshot JVM settings #  JVM memory areas:\n  code\n  stack\n  heap (is where Java programs allocated and deallocated transient memory)\n  GC refers to when the JVM reclaims the deallocated memory in the heap\n  Settings:\n MAX_HEAP_SIZE (set to max of 8 gb)  large heaps can introduce GC pauses that lead to latency   HEAP_NEWSIZE (set to 100MB per core)  the larger this is, the longer GC pauses time will be; the shorter it is, the more frequently GC will run    Garbage collection #  DSE 6+ keeps one core available for GC and other maintanance activities\nWhat consider when tuning GC:\n pause time  length of time the collector stops the application while it frees up memory   throughput  determined by how often the GC runs and pauses the application more often the GC runs, the lower throughput   we want to minimize length of pauses as well as frequency of collection  JVM available memory:\n Permanent generation new generation (ParNew)  contains:  eden 2 survivor spaces   once eden fills up with new object, JVN trigger a minor GC a minor GC stops execution, iterates over the objects in eden, copies any object that are not (yet) garbage to the active survivor space, and clears eden if the minor GC fills up the active survivor space, it performs the same process on the survivor space objects that are still active are moved to the other survivor space, and the JVM clears the old survivor space it\u0026rsquo;s a stop-the-world algorithm fast:  findong and removing garbage   slow:  moving active objects from eden to survivor space moving active objects from survivor spaces to the old gen     old generation (CMS)  contains objects that have survived long enough to not be collected by a minor GC the CSM collector runs then 75% full    Full GC:\n multi-second GC pauses = Major collections happening if the old gen fills up before the CMS collector can finish, the application is paused while a full GC runs checks everything: new gen, old gen and perm gen significant (multi-second) pauses  Heap dump #   useful when troubleshooting high memory utilization ot OutOfMemoryErrors show exactly which objects are consuming most of the heap Cassandra starts Java with the option -XX:+HeapDumpOnOutOfMemoryError  Tuning the kernel #  Time sync\n Cassandra nodes identify valid data using timestamps  all nodes within a Cassandra cluster need to have synchronized clocks   Time Stamp Counter (TSC) is a simple register within the CPU that counts the number of clock cycles  over time, TSC will drift because the clock cycles may vary between CPUs   Network Time Protocol (NTP) is a way to synchronize CPU clocks  nodes communicate wirh a hierarchy of tine servers to djust their clock adjustments occurs every 1-20 minutes    # to view current limits ulimit -a Since Cassandra nodes don\u0026rsquo;t need to share resources, these limits are not helpful. Turn them off globally by editing limits.conf. Limits take effect when you login. For Ubuntu, use root intead of *.\n *-nofile 1048576 *-memlock unlimited *-fsize unlimited *-data unlimited *-rss unlimited *-stack unlimited *-cpu unlimited *-nproc unlimited *-as unlimited *-locks unlimited *-sigpending unlimited *-msgqueue unlimited  Swap:\n for cassandra, swapping if a very bad event you are better having a node go down than limp along swapping to thoroughly disable swap:  turn off swap for the current kernel process remove swap entries from fstab change the swappiness setting   you can check the current list of swap devices by:  swapon -s  you can turn off swap without rebooting this command will not persist (i.e. will not survive a reboot):  swapoff -a  to look at the current swappiness settings use:  cat /proc/sys/vm/swappiness  this lavlue has range of 0-200 (0 is low an 200 is high) to make sure your kernell deiables swapping after a reboot, edir /etc/sysctl.conf change or add a line to set vm.swappiness = 0 use sysctl -p to get the kernel to reload the changes nade to /etc/sysctl.conf  Changing network kernel settings\n net.ipv4.ip_local_port_range = 10000 65535 net.ipv4.tcp_window_scaling = 1 net.ipv4.tcp_rmem = 4096 87380 16777216 net.ipv4.tcp_wmem = 4096 65536 16777216 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 net.core.netdev_max_backlog = 2500 net.core.somaxconn = 65000  Hardware selections #   persistent storage type  avoid:  SAN storage NAS diveces NFS   Need to use SSD   memory  for both bare metal and VMs:  prod: 16-64GB; the minimum is 8GB dev in non-loading testing environments: no less than 4GB   more memory means:  better read performanse due to caching memtables hold more recently written data     CPU  cassandra if highly concurent and uses as many CPU cores as available prod:  for bare metal: 16-core CPUs are the current price-performance sweet spot   dev:  2-4 core CPUs     network  you should bind your OS interface to separate NetworkInterface Card (NIC) recommended bandwidth os 1000 Mbits/s or grater native protocols use the native_transport_address cassandra\u0026rsquo;s internal storage protocol uses the listen_address    Security considerations #  Authentication #   desabled by default when enabled, client programs must supply a username and password: enable in dse.yaml  Apache Cassandra supports only pluggable authentication mechanisms.\nDseAuthenticator options has three schemes:\n internal  need to restart the node(s) loggin as cassandra with password cassandra the cassandra user is a superuser - has all permissions:  change the default cassandra password Cassandra stores the credentials in the sys_auth keyspace, so lossing data here could be disastrous      ALTER USER cassandra WITH PASSWORD \u0026#39;new_pass\u0026#39;; ALTER KEYSPACE \u0026#34;system_auth\u0026#34; WITH REPLICATION = {\u0026#39;class\u0026#39;: ;NetworkTopologyStrategy\u0026#39;, \u0026#39;dc1\u0026#39;: 2};  LDAP Kerberos  Cassandra users:\nCREATE TABLE system_auth.roles ( role text PRIMARY KEY, can_login boolen. is_superuser boolen, member_os set\u0026lt;text\u0026gt;, salted_hash text ) Role operations:\nCREATE ROLE SomeRole WITH PASSWORD = \u0026#39;some_pass\u0026#39; AND LOGIN = true; LIST ROLES; DROP ROLE SomeRole; Auth best practices:\n create a second superuser role change the default cassandra password and forget it be sure to replicate system_auth keyspace  Authorisation #  GRANT SELECT ON someKeyspace.someTable to somerole; Permissions:\n ALTER  A. KEYSPACE A. TABLE CREATE INDEX DROP INDEX   AUTHORIZE  GRANT REVOKE   CREATE  C. KEYSPACE C. TABLE   DROP  D. KEYSPACE D. TABLE   MODIFY  INSERT DELETE UPDATE TRUNCATE   SELECT  SELECT    OpsCenter and Lifecycle #  WebUI for DSE\nLife Cycle manager (LCM) - mostly configuration and deployment OpsCenter Monitoring - monitoring and management\n"});index.add({'id':12,'href':'/docs/mooc/datastax_academy/casandra_foundations/','title':"DS201: DataStax Enterprise 6 Foundations of Apache Cassandra™",'section':"Courses notes",'content':"# How to start bin/cassandra # for core version ./dse cassandra # for DSE version bin/nodetool status # provide with cluster health info CQL Fundamentals #  -- CQL - very similar to SQL SELECT * FROM USERS; -- Keyspaces - very similar to schemas in RDBMS; it is top level namespace/container; replication parameters required; contains tables CREATE KEYSPACE some_keyspace WITH REPLICATION = { \u0026#39;class\u0026#39;: \u0026#39;SimpleStrategy\u0026#39;, \u0026#39;replication_factor\u0026#39;: 1 }; -- USE switches between keyspaces USE other_keyspace; -- Tables contain data CREATE TABLE table1 ( column1 TEXT, column2 TEXT, column3 INT, PRIMARY KEY (column1) ); -- INSERT syntax similar to SQL syntax INSERT INTO users (user_id, first_name, last_name) VALUES (uuid(), \u0026#39;John\u0026#39;, \u0026#39;Doe\u0026#39;) -- SELECT also similar to SQL syntax SELECT * FROM users; SELECT first_name, last_name FROM users; SELECT * FROM users WHERE user_id = some_uuid_value; -- COPY - uses to import/export data between tables and CSV files COPY table1 (column1, column2, column3) FROM \u0026#39;table1data.csv\u0026#39;; -- Header parameter skips the first line in the file COPY table1 (column1, column2, column3) FROM \u0026#39;table1data.csv\u0026#39; WITH HEADER=true; -- TRUNCATE - removes table TRUNCATE table; -- Get info about table DESCRIBE table; Core datatypes #   text:  UTF8 encoded strings varchar is same as text   int:  signed 32 bits   timestamps:  date and time 64 bit integer stores number of seconds in UNIX epoch   UUID  generate via uuid()   TIMEUUID  contains timestamp value sortable generate via now()    UUID and TIMEUUID - used place of integer IDs because Cassandra is a distributed DB\nPartitions #  Tables sorted by partition key and splited for parts by its value over the cluster nodes. Partition key - first value of primary key\nClustering columns #  This is other half of primary key; they used for sorting data in partitions\n Primary key - is the most important part of your data model in Cassandra\n You can\u0026rsquo;t change primary key if you already have data in table, because in this case you need to redo your data model\nThere might be multiple cluster columns in table\nTo prevent collisions, also need to add to the primary key some uuid field.\nEvery query should have a pertition key\nYou can perform either equality (=) or range queries (\u0026lt;, \u0026gt;) in clustering columns\nAll equality comparisons must come before inequality comparisons\nSince data is sorted on disk, range searches are a binary search followed by a linear read\nChanging default ordering #  By default clustering columns ordered by ascending\nChange ordering direction via WITH CLUSTERING ORDER BY\nMust include all columns including an up to the columns you wish to order descending\nCREATE TABLE users ( state text, city text, name textm id uuid, PRIMARY KEY((state), sity, name, id)) WITH CLUSTERING ORDER BY (city DESC, name ASC); ) Node #  This is strongly recommend to store Casandra data on the local storage, not on SAN (or sort of)\nNode stores all data in distributed hash tables\nApproximate performance of one node - 6000 - 12000 transactions/second/core. Also, one node can effectively store - 2-4 TB of data\nNodetool #  Tool for node management. Located in ${install_root}/bin/\nSub-commands:\n help info status describecluster getlogginglevels setlogginglevel settraceprobability 0.1 drain stopdaemon flush  Ring #  Ring - name of Cassandra cluster.\nEach node handle specific range of all stored in a cluster data. Coordinator - node, which receives data from a client and after that it transmit data to the node, which handle right range,\nJoining the Cluster #  Nodes join the cluster by communicating with any node. Cassandra finds these seed nodes list of possible nodes in cassandra.yaml Seed nodes communicate cluster topology to the joining node. Node the new node joins the cluster, all nodes are peers.\nNode states:\n joining leaving up down  Drivers #  Drivers may choose which node would base coordinate a request\nDiver policies:\n TokenAwarePolicy - driver chooses node which contains the data RoundRobin - driver round robin the ring DCAwareRoundRobinPolicy - driver round robins the target data center  Vnodes #  With Vnodes, each node is now responsible for multiple smaller slices of the ring, instead of the one large slice.\nWhen new node joins to the ring, each current node streams few slices to it in parallel. And now the new node will responsible for this slices.\nAdding/removing nodes with vnodes helps keep the cluster balanced. By default, each node has 128 vnodes. VNodes automate token ring assignment.\nNumber of vnodes may be configured in cassandra.yaml with num_tokens parameter. Each value greater than one turns on vnodes.\nGossip #  Gossit - broadcast protocol\n Each node initiates a gossip round every second pick on to three nodes to gossip with nodes can gossip with ANY other node in the cluster fault tolerant - continues to spread when nodes fail  Gossip spreads only node metadata, not the client data.\nEndpoint State:\n  Heartbeat State:\n generation (time since node bootstrapped) version (increments every second after gossip with ather node)    Application State (stores node metadata):\n STATUS:  BOOTSTRAP NORMAL LEAVING LEFT REMOVING REMOVED   DC (datacenter) RACK SCHEMA (number of schema changes) LOAD (disk space usage) etc    SYN digest schema - endpoint_ip:generation:version (i.e. 127.0.0.1:100:20)\n  ACK also stores digest of outdated info\n  ACK2 - send only updated info.\n  nodetool gossipinfo SELECT peer, data_center, host_id, preferred_ip, rack, release_version, rpc_address, schema_version FROM system.peers; Snitch #   Determines/declares each node\u0026rsquo;s rack and data center The \u0026ldquo;topology\u0026rdquo; of the cluster  There are several types of snitches:\n Regular:  SimpleSnitch  default snitch places all nodes in the same datacenter and rack (datacenter1 and rack1)   PropertyFileSnitch  reads dc and rack info for all nodes from a file you must keep files in sync with all nodes in the cluster cassandra-topology.properties file   GossipingPropertyFileSnutch (the most popular type)  declare the current node\u0026rsquo;s DC/Rack info in a file you must set each individual node\u0026rsquo;s settings but you don\u0026rsquo;t have to copy settings as with property file snitch Gossip spreads the settings through the cluster cassandra-rackdc.properties file   RackInferringSnitch  infers the rack and DB from the IP address:  2nd octet is DB octet 3rd - rack octet 4th - node octet     DynamicSnitch  layered on top of your actual snitch maitains a pulse of each node\u0026rsquo;s performance determones which node to query replicas from depending on node health turned on by default for all snitches     Cloud Based:  Ec2Snitch Ec2MultiRegionSnitch GoogleCloudSnitch CloudstackSnitch    Configured on cassandra.yaml:\nendpoint_snitch: SimpleSnitch Configuring snitches #   All nodes in the cluster must ust the same snotch Changing cluster network topology requires rastarting all nodes Run sequential repair and clean up on each node  Replication #  With replication factor (RF) 2, each node stores not only its own data, but also its neighbour data. And in this case, coordinator writes data on two nodes.\nWith RF=3, each node stores also data of the neighbour of the neighbour.\nConsistency #  CAP theorem; Cassandra choose Partition Tolerance and Availability.\nConsistency levels - number of acknowledges from the target node to the coordinator during the data writing.\n any (storing a hit at minimum is satisfactory) one, two, three quorum local_one (the closest node to coordinator in the same dc) local_quorum (only for one dc) each_quorum (quorum of nodes in each dc, applies to write only) all  -- cql operator/cqlsh command CONSISTENCY # determine which nodes hold the replicas of the partition tag nodetool getendpoints keyspace_name table_name \u0026#39;partition_key_name\u0026#39; Hinted handoff #  If replica node is down, coordinator stores the data until replica will back online.\nSettings:\n cassandra.yaml you can disable hinted handoff choose a directory to store hints file set the amount of time a node will store a hint default is three hours  Read repair #  With Cassandra, you can choose between absolutely synced with each others node and highly available nodes.\nRead with CL=all:\n coordinator reads data from the closest node and request digest (data\u0026rsquo;s checksum) from others replicas coordinator compares data and checksums and if they equal, sends data to the client. if checksums don\u0026rsquo;t compare:  coordinator finds out a timestamp from received data requests full data from all replicas to compare its timestamps after finding the latest version of data, coordinator sends it to the outdated replicas and to the client.    Read repair chance:\n performed when read is at a consistency level less then ALL request reads only a subset of the replicas we can\u0026rsquo;t be sure replicas are in sync generally you are safe, but no guarantees response sent immediately when consistence level is met read repair done asynchronously in the background dclocal_read_repair_chance set to 0.1 (10%) by default  read repair that is confined to the same DC as the coordinator node   read_repair_chance set to 0 by default  for a read repair across all DCs with replicas    Nodetool repair #   syncs all data in the cluster expensive  grows with an amount of data in cluster   use with a cluster servicing high writes/deletes last line of defense run to synchronize a failed node coming back online run on nodes not read from very often  Node sync #  Full repairs:\n full repairs bog down the system bigger the cluster and dataset. the worse the time in times past, we recommended running full repair within gc_grace_seconds  Node sync:\n Runs on the background continuously repairing you data  quiet hub vs everybody stops what you\u0026rsquo;re doing   better to repair in small chunks as we go rather than full repair automatic enabled by default (in DataStax version)  by you must enable it per table   each node runs NodeSync NodeSync continuously validates and repairs data  CREATE TABLE myTable (...) WITH nodesync = {\u0026#39;enabled\u0026#39;: \u0026#39;true\u0026#39;}; Save Points:\n each node splits its local range into segments  small token range of a table   each segment makes a save point  NodeSync repairs a segment then NodeSync saves its progress repeat   NodeSync priorities segments to meet the deadline target  Segments sizes:\n determining token range in a given segment is a simple recursive split target is each segment is less than 200MB  configurable, but good default, segment_size_target_bytes greater than a partition so partitions greater than 200MB win over segments less than 200MB   algorithm doesn\u0026rsquo;t calculate data size but instead assumes acceptable distribution of data among your cluster  Segment failures\n nodes validate/repair segments as a whole if node fails during segment validation, node drops all work for that segment and starts over node records successful segment validation in the system_distributed.nodesync_status table  Segment outcomes\n full_in_sync: all replicas ware in sync full_repaired: some repair necessary partial_in_sync: not all replicas responded (at lest 2 did), but all respondent ware in sync partial_repaired: not all replicas responded (at least 2 did), with some repair needed uncompleted: one node available/responded; no validation occured failed: inexpected error happend; check logs  Segment validation:\n NodeSync simply performs a read repair on the segment read data from all replicas check for inconsistencies repair stale nodes  Write path #  Writes:\n MemTable (in RAM)  always ordered by partition key and clustering column   Commit Log (on disk)  stored sequentially, every record just append to the commit log   After the data stored into MemTable and Commit log, Cassandra sends acknowledge to the client When MemTAble is full, it flushes to the disk and this structure called SSTable (and now this structure is immutable) After that, Cassandra deletes Commit log, because it already has sorted data on the disk  It\u0026rsquo;s recommended to store Commit Log on different storage as SSTables\n# run stress test cassandra-stress write no-warmup n=250000 -port native=9041 -rate threads=1 # show data of the stress test nodetool cfstats keyspace1.standard1 Read path #  Reads:\n from MemTable:  just find value in MemTable with binary search   from SSTAble:  SSTAble file has an index file, which stores partition token and its offset in bytes Partition summary - im memory index of partition indexes result of read is stored in key cache for case if client want to read similar data next time    Bloom filter #  need to google it !!1!\nDSE Read Path Optimizations #   no partition summary partition index changed to a trie-based data structure SSTable lookups in this format scream! huge performance improvements; especially for the large SSTables  Compactions #  Compaction is a process of merging few SSTables into one SSTable.\nDuring compaction Cassandra selected more recent data (with greater timestamps) When you delete data? Cassandra actually writes a tombstone instead deleted record, so during compaction if this record timestamp is greater than 10 days (by default, configurable in cassandra.yaml), it will skipped, in other case it will write to result file.\nCompaction strategies #   Compaction strategies are configurable. These strategies include:  Size Tiered Compaction (default) - triggers when multiple SSTables of a similar size are present Leveled Compaction - groups SSTables into levels, each of which has a fixed size limit which is 10 times larger than the previous level TimeWindow Compaction - creates time windowed buckets of SSTables that are compacted with each other using the Size Tiered Compaction Strategy   Use the ALTER TABLE command to change the strategy  ALTER TABLE myKeySpace.myTable WITH compaction = {\u0026#39;class\u0026#39;: \u0026#39;LeveledCompactionStrategy\u0026#39;}; "});index.add({'id':13,'href':'/docs/k8s/foundation_of_kubernetes/','title':"Foundation of Kubernetes",'section':"Kubernetes",'content':"https://github.com/amorozov87/kubernetes-traning\nKubernetes quick start #  K8S - opensource система оркестрации контейнеров\nОсновная задача - распределять (по нодам) и менеджить контейнеры с приложениями\nПредоставляет:\n service discovery load balancing autoscaling (как приложения, так и самого кластера) HA декларативный механизм обновлений полезной нагрузки  Контроллер - демон, следящий за состоянием некоторого объекта, например приложения, которое задеплоили\nConceptions #   nodes - узлы кластера  master - нода, на которой задеплоен control plane worker - нода с бизнес приложениями   namespace - виртуальное кластерное пространство внутри одного кластера; нужен для логического разделения задеплоенных приложений pods - базовая сущность кластера, абстракция над одним или несколькими контейнерами controllers  controller manager - основной контроллер кластера, входящий в control plane operator - кастомный контроллер; пишется самостоятельно   labels volumes jobs - одноразово запущенный контейнер, который будет рестартоваться только если процесс завершился с ненулевым кодом выхода (обычный контейнер будет рестартоваться при любом завершении процесса) kubectl - утилита управления кластером  Кластерная роль затрагивает весь кластер. Простая роль доступна только в том неймспейсе, в котором она создана.\nРоль даёт права на выполнение каких-либо действий (внутри неймспейса)\nПравили роли:\n verbs - действия, которые мы можем выполнять apiGroups - каждая сущность кластера имеет собственное API (пустое значение означает, все существующие группы) resources - ресурсы кластера, к которым можно применять перечисленные действия  Роли могут наследовать правила\nKubernetes cluster architecture #   master - содержит весь control plane  etcd - KV db, содержит весь стейт кластера; работает по принципу кворума, поэтому должно быть нечетное количество экземпляров API server - центральное звено, все запросы идет через него; для настройки HA требуется внешний балансер, так как kubelet не может смотреть в несколько API серверов Scheduler - отвечает за распределение подов по кластеру; * Controller Manager - следит за работой компонентов control plane; *   worker node  Container engine, например Docker Kubelet - агент, общается с API сервером и управляет подами на локальной ноде; ответственен за то, чтобы состояние рабочей нагрузки соответствовало тому, что указано для нее на API сервере Kubernetes proxy - отвечает за сетевое взаимодействие внутри кластера    * - умеют самостоятельно выбирать лидера в HA-режиме\nОсновная сетевая концепция Kubernetes - любой под должен быть доступен для любого другого пода напрямую, без участия NAT`а\nDeployment exposed #  Namespace #  Создавался для разграничение энвайроментов с большим количеством пользователей.\nРесурсы уникальны в рамках неймспейса.\nОбладает своими квотами.\nkubectl completion -h # добавление автодополнения kubectl get ns # список неймспейсов kubectl create ns $NS_NAME # создание неймспейса kubectl edit clusterrole $ROLE_NAME # редактирование роли Deployment #  Сущность, которая отвечает за абстракцию над задеплоеным приложением\nПредоставляет декларативные механизмы апдейтов для подов и replicaSet`ов\nменяет актуальное состояние на декларированное\nиспользование дейлойментов - best practice, так как при создании отдельных подов, отсутствует автоматический механизм контроля за его состоянием\nпри обновлении дейплоймента создается новый replicaSet и появляется возможность быстро откатиться к предыдущему состоянию\nDeployment workflow:\nYAML\\JSON Template -\u0026gt; Deployment -\u0026gt; ReplicaSet -\u0026gt; Pod -\u0026gt; Containers kubectl create deployment deploymentName --image=imageName kubectl delete deployment deploymentName Deployment use cases #   развернуть replicaSet задекларировать новое состояние для подов откатиться на более раннюю версию деплоймента масштабировать дейлоймент приостановить деплоймент для применения множественных фиксов (вероятно не применяется на практике) просмотр статуса деплоймента  Pods and Containers #    базовый \u0026ldquo;строительный блок\u0026rdquo; кластера\n  абстракция над одним или несколькими контейнерами\n  всегда имеет уникальный в пределах кластера IP-адрес\n  контейнеры в рамках одного пода:\n всегда расположены на одной ноде имеют единый сетевой неймспейс, соответственно всегда общаются напрямую друг с другом    Init containers #  Специализированный контейнер, который стартует перед контейнером с приложением\n могут содержать и запускать дополнительные утилиты, которые не желательно включать в основной контейнер с приложением (например по соображениям безопасности) предоставляют механизм контролируемой задержки старта основного контейнера  Services (discovery) #  Это абстракция, которая определяет логический набор подов и политики доступа к ним. Поды определяются по лейблам.\nТипы сервисов:\n Normal - имя сервиса резолвится в IP кластера Headless - резолвится напрямую в IP-адрес пода  Пример сервиса:\nkind: Service apiVersion: v1 metadata: name: nginx-service spec: clusterIP: None # для создания headless сервиса selector: app: nginx ports: - protocol: TCP port: 80 targetPort: 80 В качестве протоколов поддерживаются TCP (по умолчанию) и UDP\nСервис без селектора нужен для того чтобы K8S мог ссылаться на внешние объекты. Примеры использования:\n использование внешней БД в проде и внутренней в тесте использование сервиса в другом неймспейсе миграция нагрузки с K8S на сторонние бакенды  Для такого сервиса EndPoint не будет создан автоматически.\nСпособы открыть доступ к сервису:\n ClusterIP  открывает доступ по внутреннему кластерному IP соответственно, в этом случае сервис доступен только внутри кластера дефолтный тип   NodePort  открывает доступ к сервису по адресу ноды на статическом порте с ним можно общаться снаружи ${NodeIP}:${NodePort}   LoadBalancer  открывает доступ к сервису снаружи с использованием LA, предоставляемого облачным провайдером    kubectl patch... # обновление ресурсов Ingress #   Предоставляет доступный извне URL Балансирует трафик (RR) Терминирует SSL-соединение предоставляет основанный на именах виртуальный хостинг требует наличия Ingress-контроллера (одна из имплементаций - NGINX)  Типы ингрессов:\n Single service ingress Simple fanout Name based virtual hosting  Running you app #  Dry run #  Опция kubectl, которая только печатает объект, который должен был бы быть отправлен.\nkubectl create deployment deploymentName --image=imageName --dry-run=true kubectl create deployment deploymentName --image=imageName --dry-run=true -o yaml \u0026gt; deployment.yaml # пример создания файла деплоймента Using env vars #  При создании пода можно установить переменные окружения, которые будут переданы в контейнер.\nspec: containers: ... env: - name: DEMO_KUBERNETES value: \u0026#34;Hello from k8s\u0026#34; Также можно передавать в переменные окружения информацию о самом контейнере:\n metadata.name metadata.namespace metadata.labels metadata.annotations spec.nodeName spec.serviceAccountName status.hostIP status.podIP  spec: containers: ... env: - name: MY_NODE_NAME valueFrom: fieldPath: fieldPath: metadata.name Commands and arguments #  Аналог ENTRYPOINT и CMD инструкций Docker. Задаются в полях command и args конфига. Не могут быть изменены после того, как Под был создан.\nПеретирают дефолтные команды и аргументы, которые указаны при сборке образа.\nЕсли указаны только аргументы, дефолтная команда из образа будет использована с новыми аргументами.\n   Description Docker field Kubernetes field     Команда, которая будет запущена контейнером Entrypoint command   Аргументы, которые будут переданы команде Cmd args       Image Entrypoint Image Cmd Container command Container args Command run     [/ep1] [foo bar]   [ep-1 foo bar]   [/ep1] [foo bar] [/ep-2]  [ep-2]   [/ep1] [foo bar]  [zoo boo] [ep-1 zoo boo]   [/ep1] [foo bar] [/ep-2] [zoo boo] [ep-2 foo bar]    Scheduling #  Механизмы распределения Подов:\n все механизмы используют лейблы Node Selector (позволяет указать, что деплоймент должен быть размещен на ноде с определенным лейблом; устаревший)  можно объединять несколько лейблов    spec: nodeSelector: labelName: labelValue  Node affinity and anti-affinity (похож на первый, но более гибкий)  позволяет операции над лейблами:  And In NotIn Exists DoesNotExists Gt Lt   правила бывают:  soft/preferred - предпочтение отдаётся нодам с указанными лейблами, но если они недоступны, под будет задеплоен на любую доступную ноду hard/required - требуется полное соответствие лейблам   все правила применяются только в момент деплоя пода, позднейшие изменения не будут иметь эффекта, пока под не будет передеплоен под может быть задеплоен на ноду, если одно из условий nodeSelectorTerms удовлетворено \u0026ndash;--, если все условия matchExpressions были удовлетворены    spec: ... spec: affinity: requiredDuringSchedulingInnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: lableName operator: In values: - labelValue  inter-pod affinity and inti-affinity  аналогично, но с подами, а не с нодами вариант применения - исключить деплой реплик приложения на одну ноду   Taints  имеет:  ключ значение эффект  NoSchedule PreferNoSchedule NoExecute       Tolerations  имеет: ключ значение оператор  Exists Equal   эффект    Image pull policies #   ifNotPresent(DEFAULT) - скачивает образ, если его нет в локальном кеше той ноды, куда приезжает приложение Always(:LATEST) Never  Application restarts #   Always (default) OnFailure Never  Применяется ко всем контейнерам в поде. Поды рестартуют с экспоненциальной дажержкой (10с, 20с, 40с\u0026hellip;)\nApplication logs #  kubectl logs ${podName} --\\\\-- --previous # следует использовать в случае, если контейнер завалился Если под имеет несколько контейнеров, то нужно указывать имя конкретного контейнера.\nЕсли контейнер рестартует, k8s сохраняет один остановленный контейнер с логами.\nЕсли под выселяется с ноды, то все относящиеся к нему контейнеры выселяются вместе с логами.\nВ логи пишется только stdout и stderr PID1\nApplication scaling #  Replica sets #  Может использовать независимо от других сущностей\nНо рекомендуется использовать деплойменты, так как в этом случае, не нужно следить за жизнью контейнера\nОписывает конкретное число подов с приложением, которое должно существовать в конкретный момент времени\nScaling #   по дефолту стартует один под можно скейлить до нуля (выключение) пропорциональное обновление  Autoscaling #  kubectl sutoscale deployment podName  предствален в виде отдельно ресурса и контроллера дефолтное значение задержки 30 сек собирает как ресурсные метрики, так и кастомные заданный процент потреблённых ресурсов высчитывается от requests (см. ниже); если это значение не задано, работать не будет  Compute resources managing #  containers: ... resources: requests: memory: \u0026#34;64Mi\u0026#34; cpu: \u0026#34;250m\u0026#34; limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; Updating an application #  Deployment update #   Kubectl set image  kubectl run nginx --image=nginx:1.12 --replicas=3 kubectl rollout status deploy nginx kubectl set image deploy nginx nginx=nginx:1.13  Kubectl edit  kubectl edit deploy nginx kubectl rollout status nginx  Kubectl apply  kubectl get deploy nginx -o yaml \u0026gt; nginx_deploymetn.yaml kubectl apply -f nginx_deployment.yaml kubectl rollout status deploy nginx  У k8s есть политика, говорящая сколько подов может быть недоступно в ходе апдейта \u0026ndash;\\\u0026ndash;, может быть создано сверх желаемого значение раскатка деплоймента стриггерится только, если поменялся сам шаблон (изменение метадаты к этому не приводит) каждый раз создается новый ReplicaSet  Deployment rollouts and rollbacks #   Rollout  kubectl apply -f nginx_deployment.yaml --record kubectl rollout status deploy nginx kubectl get deployments  Update  kubectl set image deploy nginx nginx=nginx:1.13 --record=true kubectl rollout status deploy nginx kubectl get pods  Rollback  kubectl rollout history deploy nginx kubectl history deploy nginx --revision=2 kubectl rollout ubdo deploy nginx The deployment lifecycle #   Pregressing  создается новый ReplicaSet поднимается новый ReplicaSet тушится старый ReplicaSet   Complete  все реплики обновлены до последней версии все реплики доступны ни одна старая реплика не запущена   Failed  insufficient quota insufficient permissions readiness probe failures image pull errors limit ranges application runtime misconfiguration    Dealing with storage #  Empty dir #   создается, когда под добавляется на ноду существует, пока под запущен на ноде изначально пустой может быть смонтирован по тому же или отличающемуся пути когда под (по любой причине) удаляется с ноды, данные их emptyDir удалятся безвозвратно  spec: containers: ... volumeMounts: - mountPath: /cashe name: cache-volume volumes: - name: cache-volume emptyDir: {} Host path #   монтирует директорию с хостовой машины может вести себя по разному на различных нодах (поэтому не рекомендуется в проде) нужны привелегии для использования  Git repo #   монтирует пустую директорию и клинирует в нее репу  Persistent volumes #   абстракция над работой с хранилищем может быть запровиженен как автоматически, так и администратором PersistentVolumeClaim (PVC) - запрос на хранилище со стороны пользователя StorageClass - механизм автоматического привиженинга  Application configuration #  Configmap #  Объект k8s, предоставляющий механизм хранения KV данных.\nМожет быть использована как:\n аргумент командной строки переменна окружения файл в волюме  kubectl create configmap nginx-config --from-file=/path/to/dir # k - имя файла, v - содержимое файла kubectl create configmap nginx-config --from-file=/path/to/file # k - имя файла, v - содержимое файла kubectl create configmap nginx-config --from-file=${myKeyName}=/path/to/file kubectl create configmap nginx-config --from-literal=someKey=someValue Директивы \u0026ndash;from-file и \u0026ndash;from-literal можно совмещать.\nИспользование:\n env var:  from a single ConfigMap from multiple ConfigMaps   in pod commands:  echo ${KEY_NAME} (правда нужно предварительно создать переменную окружения)   volume:  монтирование тома с данными, сохраненными в ConfigMap добавление ключей ConfigMap в конкретный путь на томе    Secrets #  Аналогично, но хранится в зашифрованном виде\nОграничения:\n должны быть созданы до пода должны быть созжаны в том же неймспейсе каждый секрет не может быть больше 1 мб  Jobs and daemons #  Jobs #   отдельный ресурс со своим контроллером создает один или несколько подов, обеспечивая успешное выполнение указанной в образе команды как только задача успешно завершается, удаляются все поды, относящиеся к ней если задача завершается с ненулевым кодом ответа, под рестартуется (с экспоненциальной задержкой) поды могут выполнять задачу параллельно  Daemons sets #   обеспечивают запуск одному экземпляру пода на каждой (или некоторых) нодах если в кластер будет добавлена новая нода, приложение приедет и на нее (с учетом всех ограничений шедулинга) удаление Daemon set приведет к удалению всех подов  Примеры использования:\n storage daemon (glusterfs, ceph, etc) агенты агрегатора логов мониторинг агенты  Stateful applications #   StatefulSet - разрабатывался для обслуживания stateful приложений и распределенных систем предоставляет гарантии очередности старта подов каждый под представляет из себя уникальный объект спецификации подов такие же как в деплойменте, но поды не взаимозаменяемые каждый под имеет собственное не шареное хранилище каожый под имеет уникальное имя вида ${StatefulSetName}-${Ordinal}  Ограничения:\n удаление не удаляет хранилища требует Headless сервис, так как обычно распределенные приложения плохо работают с прокси  Политики управления подами:\n OrderedReady (default) Parallel  Стратегии обновления:\n On Delete Rolling Updates Partitions  "});index.add({'id':14,'href':'/docs/misc/old_hardware/','title':"Old hardware",'section':"Docs",'content':"Old hardware notes #  Compaq Evo n600c #  Solaris 9 notes #  How to add on-board network interface in the system:\necho \u0026#39;iprb \u0026#34;pci8086,1038\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/driver_aliases ifconfig iprb0 plumb # OR \u0026#34;touch /reconfigure; init 6\u0026#34;, but bit I didn\u0026#39;t check this method echo `hostname` \u0026gt; /etc/hostname.iprb0 sync reboot Source\nAnd configure this interface to using dhcp:\n Edit /etc/default/dhcpagent by root user ( previously need to add write permissions to this file ). Need to uncomment and modify entry:  RELEASE_ON_SIGTERM=yes Create appropriate interface file to enable dhcp:  touch /etc/dhcp.iprb0 Reboot the machine.  Source\n"});index.add({'id':15,'href':'/docs/languages/','title':"Languages",'section':"Docs",'content':"Notes about different programming languages #  "});index.add({'id':16,'href':'/docs/languages/scala/','title':"Scala",'section':"Languages",'content':"Scala #  Переменные #  val x // константа def x // вычисляются каждый раз, когда на них ссылаются lazy val x // вычисляется не больше одного раза в момент первого к ней обращения var x // \u0026#34;настоящая\u0026#34; переменная, которая может быть переопределена Области видимости #  { val x = \u0026#34;Inner\u0026#34; println(x) } println(x) // Error!!1! Пространства имен #  Идентификаторы: #   стабильные  package параметр функции val lazy val object   нестабильные:  def    Импортирование: #  import com.example.Module.{name1, name2} // нескольких сущностей из пакета import com.example.Module._ // все имена из пространства import com.example.Module.{name1 =\u0026gt; newName} // переименование при импорте import com.example.Module.{_, name1 =\u0026gt; _} // импортирование всех имен, кроме указанных Типы #  A \u0026lt;: B // Тип А является подтипом типа В, когда все значения А могут использоваться как значения типа В.  A \u0026lt;: Any // Надтип для любого другого типа  A \u0026lt;: AnyRef // Надтип для любых ссылочных типов A \u0026lt;: AnyVal // Надтип для любых примитивных типов  val x: String = \u0026#34;Some string\u0026#34; val y: AnyRef = x val z: Any = y val a: Int = 4 val b: AnyVal = a val c: Any = b Nothing \u0026lt;: // является подтипом любого типа, в основном используется при генерации ошибок Примитивные типы: #   Целые числа (знаковые)  Byte (1 byte) Short (2 byte) Int (4 byte) Long (8 byte)   Дробные числа:  Float (4 byte) Double (8 byte)   Символы  Char (2 byte)   Булевы значения:  Boolean   Единичный тип:  Unit (значение этого типа константно, используется, например, для типа значения, возвращаемого из функции, если оно нас не интересует)    Числа #  val a = 3 // Int val b = -5L // Long val c = 10.0 // Double val d: Float // Явно указанный Float val e = 1.03e1 // Вариант записи с мантиссой (научная форма записи) Алгебраические операции с числами: #  val x = -5 val y = 3 x + y // Сложение x - y // Вычитание x * y // Умножение x / y // Целочисленное деление x % y // Взятие остатка -x // Унарный минус Побитовые операции с числами: #  val x = 0xF val y = 0XA1 x \u0026gt;\u0026gt; y // побитовый сдвиг вправо x \u0026lt;\u0026lt; y // -//- влево x | y // -//- ИЛИ x \u0026amp; y // -//- И x ^ y // -//- исключающее ИЛИ ~x // -//- инверсия Порядок операций (по возрастанию, определяется по первому символу оператора) #   символы | ^ \u0026amp; = ! \u0026lt;\u0026gt; : + - * / % все остальные знаки  Ссылочные типы для больших чисел #  val x = BigInt(10) // Целочисленный тип, содержащий неограниченное количество цифр val y = BigDecimal(10) // Дробное число, так же не ограниченное по длине val z = BigInt(\u0026#34;1000\u0026#34;) // Эти типы могу быть инициализированы как числом, так и строчным представлением числа  x pow 100 // Операция возведения в степень для BigInt, не дающая переполнения x gcd y // Нахождение наибольшего общего делителя для двух больших чисел Булевые значения #  val a = true val b = false Операции сравнения: #  val a = 1 \u0026gt; 5 // Больше val b = 1 \u0026lt; 5 // Меньше val c = 1 \u0026lt;= 5 // Меньше или равно val d = 1 \u0026gt;= 5 // Больше или равно val e = 1 == 5 // Равно val f = 1 != 5 // Не равно Логические операции: #  val x = 1 \u0026gt; 5 val y = \u0026#34;Example\u0026#34; contains \u0026#34;a\u0026#34; x \u0026amp;\u0026amp; y // И x || y // ИЛИ !x // НЕ Равенство: #  Сравнивать объекты разных типов можно, но компилятор выдаст предупреждение.\nСравнение по ссылке:\nval x = \u0026#34;Te\u0026#34; val y = \u0026#34;st\u0026#34; val a = x + y val b = x + y a == b // true, так как значения одинаковые a eq b // false, так как ссылки разные В Java все константные строки интернированы: компилятор производит оптимизацию, в результате чего, одинаковые строковые литералы ссылаются на один и тот же объект в памяти. Поэтому:\nval s1 = \u0026#34;foo\u0026#34; val s2 = \u0026#34;foo\u0026#34; println(s1 eq s2) // true Строки #  val name = \u0026#34;Username\u0026#34; // Объявление строки val greet = \u0026#34;Hello\u0026#34; + name + \u0026#34;!!!\u0026#34; // Конкатенация val greet2 = s\u0026#34;Hello $name!!!\u0026#34; // Интерполяция val multiLine = \u0026#34;\u0026#34;\u0026#34; multi line string \u0026#34;\u0026#34;\u0026#34; Операции: #  val s = \u0026#34;aaabbb\u0026#34; s.startsWith(\u0026#34;aa\u0026#34;) s.endsWith(\u0026#34;bb\u0026#34;) s.contains(\u0026#34;ab\u0026#34;) s.matches(\u0026#34;a+b+\u0026#34;) // regexp Практически любой объект имеет метод toString:\nval x = 2 x.toString \u0026#34;x is \u0026#34; + x // При конкатенации приведение к строке происходит автоматически Методы #  Способ оформления переиспользуемого фрагмента кода.\ndef plusOne(number: Int): Int = number + 1 | | | | | | | | | | | +-- тело метода | | | | +-- возвращаемый тип | | | +-- тип параметра | | +-- имя параметра | +-- имя метода +-- ключевое слово // Вызов метода plusOne(4) // 5 Тип результата может быть опущен в случае, если он очевидно следует из тела метода. В этом случае тип будет выведен автоматически:\ndef plusOne(number: Int) = number + 1 Несколько параметров передаются через запятую:\ndef plusOne(x: Int, y: Int, z: Int): Int = x + y + z plusOne(1, 2, 3) // 6 У метода может быть несколько списков параметров. В этом случае при вызове метода входные параметры так же должны быть сгруппированы соответствующим образом:\ndef plusOne(x: Int, y: Int)(z: Int): Int = x + y + z plusOne(1, 2)(3) // 6 Так же у метода может не быть параметров, в этом случае, он воспринимается как \u0026ldquo;переменная\u0026rdquo;, значение которой вычисляется каждый раз при обращении (см. начало)\ndef sixty: Int = 10 * 6 sixty // 60 Тело метода может быть обернуто в фигурные скобки. Возвращено будет значение последнего выражения.\ndef plusAndPrint(x: Int, y: Int): Int = { val result = x + y println(s\u0026#34;$x+ $y= $result\u0026#34;) result } plusAndPrint(2, 4) // prints \u0026#34;2 + 4 = 6\u0026#34;, returns 6 Если метод не производит какие-либо действия, не возвращая ничего, то его возвращаемым типом будет Unit.\ndef plusAndPrint(x: Int, y: Int): Unit = { val result = x + y println(s\u0026#34;$x+ $y= $result\u0026#34;) } plusAndPrint(2, 4) // prints \u0026#34;2 + 4 = 6\u0026#34; Методы могут быть вызваны в телах других методов. В этом случае вложенный метод может ссылаться на параметры внешнего:\ndef plusMul(q: Int, x: Int, y: int): Int = { def mul(u: Int) = q * u mul(x) + mul(y) } plusMul(10, 2, 3) // 50 Последний параметр может быть объявлен повторяемым, то есть он может использоваться как коллекция:\ndef sumAllTimes(u: Int, nums: Int*): Int = u * nums.sum sumAllTimes(3, 1, 2, 3) // 3 * (1 + 2 + 3) = 18 Значение по умолчанию и именованные аргументы:\ndef plus3(x: Int, y: Int = 0, z: Int = 0): Int = 100 * x + 10 * y + z plus3(1) // 100 plus3(1, 2) // 120 plus3(1, 2, 3) // 123  plus3(x = 1) // 100 plus3(1, z = 2) // 102 plus3(x = 1, z = 3, y =2) // 123 При передаче параметра по имени его значение вычисляется не всегда а только тогда, когда в этом действительно есть необходимость. Но стоит отметить, что он будет вычислен столько раз, сколько раз на него будут ссылаться, что может привести к сложно отлаживаемым багам:\ndef replaceNegative(x: Int, z: =\u0026gt; Int): Int = if (x \u0026gt;= 0) x else z replaceNegative(1, 3 * 3 * 3) // 1 replaceNegative(-1, 3 * 3 * 3) // 27 Для рекурсивных функций указание типа обязательно\ndef sumRange(from: Int, to: Int): Int = { if ( to \u0026lt; from ) 0 else from + sumRange(from + 1, to) } sumRange(1, 10) // 55 Функции #  Функция - выражение, которое может быть использовано как метод.\nval x: Int =\u0026gt; Int = ... val y: (Int, Int) =\u0026gt; Int = ... // Максимальное количество параметров - 22 Лямбда-абстракция #  Значения функций можно задавать с помощью лямбда-синтаксиса\nval x: Int =\u0026gt; Int = x =\u0026gt; x + 1 val y: (Int, Int) =\u0026gt; Int = (x, y) =\u0026gt; x + y Тип параметров можно указывать прямо в лямбда-выражении, в этом случае компилятор попробует вывести тип самостоятельно\nval addOne = (x: Int) =\u0026gt; x + 1 val plus = (x: Int, y: Int) =\u0026gt; x + y Короткая запись может быть использована в случае, если каждый параметр используется только один раз и вызывается и все параметры вызываются в том же порядке, в котором передаются в функцию:\nval addOne: Int =\u0026gt; Int = _ + 1 val plus = (_: Int) + (_: Int) Эта-конверсия #  Еще один метод объявления функции, путем конвертации метода:\ndef addOnde(x: Int) = x + 1 val add1 = addOne _ def plus(x: Int, y: Int) = x + y val pl: (Int, Int) =\u0026gt; Int = plus // подчеркивание можно опустить, если для компилятора очевидно, что в этом месте ожидается функция "});index.add({'id':17,'href':'/docs/languages/c_sharp/','title':"C#",'section':"Languages",'content':"C# notes #  Hello world #  using System; public class Test { public static void Main() { Console.WriteLine(\u0026#34;Hello World!\u0026#34;); } } Variables #  var varName = \u0026#34;var value\u0026#34;; String varName2 = \u0026#34;another string\u0026#34;; Flow control #  if (bool condition) { ... } else { ... } "});index.add({'id':18,'href':'/docs/mooc/math/','title':"Книга для чтения по высшей математике",'section':"Courses notes",'content':"Книга для чтения по высшей математике #  Н.Л. Белая\nН.Н. Петров\nОгромное спасибо авторам за терпение, проявленное при обучении гуманитариев и за это прекрасное пособие.\n \u0026ldquo;Начала\u0026rdquo; Евклида Теория множеств Числа Комплексные числа Матрицы Аналитическая геометрия Нечёткие множества Теория пределов Производная Интеграл Дифференциальные уравнения Теория вероятностей Статистика Теория игр Теория графов  "});index.add({'id':19,'href':'/docs/languages/c/','title':"C",'section':"Languages",'content':"C notes #  Pointers #  int x = 1, y = 2, z[10]; int *ip; /* ip -\u0026gt; int*/ ip = \u0026amp;x; /* ip -\u0026gt; x */ y = *ip; /* y = 1 */ *ip = 0; /* x = 0 */ ip = \u0026amp;z[0]; /* ip -\u0026gt; z[0]*/ При передаче в функцию, переменные копируются, поэтому для изменения данных во внешней функции нужно передавать указатели.\nFile open modes #     mode description starts\u0026hellip;     r/rb open for reading (The file must exist) beginning   w/wb open for writing (creates file if it doesn\u0026rsquo;t exist). Deletes content and overwrites the file. beginning   a/ab open for appending (creates file if it doesn\u0026rsquo;t exist) end   r+/rb+/r+b open for reading and writing (The file must exist) beginning   w+/wb+/w+b open for reading and writing. If file exists deletes content and overwrites the file, otherwise creates an empty new file beginning   a+/ab+/a+b open for reading and writing (append if file exists) end    "});index.add({'id':20,'href':'/docs/misc/chromeos/','title':"ChromeOS",'section':"Docs",'content':"Chrome OS #  Crew #  Crew is a Crome OS package manager.\nProblem like this:\nchronos@localhost ~/Downloads $ crew install neovim neovim: Neovim is a refactor, and sometimes redactor, in the tradition of Vim (which itself derives from Stevie). https://neovim.io/ version 0.2.0 Precompiled binary available, downloading... curl: error while loading shared libraries: libmetalink.so.3: cannot open shared object file: No such file or directory Traceback (most recent call last): 9: from /usr/local/bin/crew:974:in `\u0026lt;main\u0026gt;\u0026#39; 8: from /usr/local/bin/crew:905:in `install_command\u0026#39; 7: from /usr/local/bin/crew:905:in `each\u0026#39; 6: from /usr/local/bin/crew:909:in `block in install_command\u0026#39; 5: from /usr/local/bin/crew:611:in `resolve_dependencies_and_install\u0026#39; 4: from /usr/local/bin/crew:697:in `install\u0026#39; 3: from /usr/local/bin/crew:430:in `download\u0026#39; 2: from /usr/local/bin/crew:430:in `chdir\u0026#39; 1: from /usr/local/bin/crew:437:in `block in download\u0026#39; /usr/local/bin/crew:437:in `read\u0026#39;: No such file or directory @ rb_sysopen - ./neovim-0.2.0-chromeos-armv7l.tar.xz (Errno::ENOENT) resolvs by:\ncrew remove curl \u0026amp;\u0026amp; crew install curl "});index.add({'id':21,'href':'/docs/languages/java/','title':"Java",'section':"Languages",'content':"Java notes #  Hello World #  public class HelloWorld { public static void main(String[] args) { System.out.println(\u0026#34;Hello, World!!!\u0026#34;); } } Import #  import com.compamy.somepackage.Name; // imports only specified package  import com.compamy.somepackage.*; // imports each class in this package,  // BUT don\u0026#39;t import classes in subpackages Infrastructure #  JRE = JVM + SE Libs\nJDK = JRE + DevTools\nData types #  Elementary (simple) data types:\n Integer  byte (8 bit, -2^7\u0026hellip;2^7-1) short (16 bit, -2^15\u0026hellip;2^15-1) int (32 bit, -2^31\u0026hellip;2^31-1) long (64 bit, -2^63\u0026hellip;2^63-1)   Float  float (32 bit, 1.4e-45\u0026hellip;3.4e+38) double (64 bit, 4.9e-324\u0026hellip;1.8e+308)   Symbol  char (16 bit)   Boolean  boolean  true false      Flow control #  if (a \u0026gt; b) { ... } else { ... } If we skip curly brackets, \u0026ldquo;else\u0026rdquo; owns only first following expression.\nType conversion #  a + b = result if a || b is double: result is double else if a || b is float: result is float else if a || b is long: result is long else: result is int Referencing subclass objects #  Let\u0026rsquo;s define few example classes:\nclass SuperClass { ... } class SubClassOne extends SuperClass { ... } class SubClassTwo extends SuperClass { ... } There are two ways to refer to a subclass object:\n Subclass reference:  SubClassOne varOne = new SubClassOne(); SubClassTwo varTwo = new SubClassTwo();  Superclass reference:  SuperClass varOne = new SubClassOne(); SuperClass varTwo = new SubClassTwo();  We cannot assign an object of one subclass to the reference of another subclass because they don\u0026rsquo;t inherit each other:  SubClassOne varOne = new SubClassTwo(); // Error!!1!  We cannot assign an object of the parent class to the reference of int subclass:  SubClassOne varOne = new SuperClass(); // Error!!1!   Polymorphism #  Polymorphism means that something (an object or another entity) has many forms.\nJava provides two types of polymorphism:\n static (compile-time; achieved by method overloading) dynamic (run-time; based on inheritance and method overriding)  Method overriding is when a subclass redefines a method of the superclass with the same name.\nThe run-time polymorphism relies on two principles:\n a reference variable of the superclass can refer to any subtype object; a superclass method can be overridden in a subclass.  "});index.add({'id':22,'href':'/docs/misc/macos/','title':"macOS",'section':"Docs",'content':"Terminal utils #  Mount (linux distro) ISO #  First we attach ISO to system:\nhdiutil attach -nomount /path/to/ISO returns something like this:\n/dev/disk2 Apple_partition_scheme /dev/disk2s1 Apple_partition_map /dev/disk2s2 Apple_HFS then mount need device to mountpoint:\nmount -t cd9660 /dev/disk2 /path/to/mount And after usage:\numount /dev/disk2 hdiutil detach disk2 Show CPU info #  # Number of CPU cores sysctl -n hw.ncpu # CPU model sysctl -n machdep.cpu.brand_string Flush DNS cache #  # Big Sur sudo dscacheutil -flushcache sudo killall -HUP mDNSResponder "});index.add({'id':23,'href':'/docs/misc/mikrotik/','title':"Mikrotik",'section':"Docs",'content':"NetInstall #  Netinstall tool originaly delevoped for Windows. I don`t test it via wine.\r Disable Firewall Connect PC to Port 1 on Mikrotik Disable all other network interfaces on the PC - LAN, Wireless, Virtualbox Set static IP of 192.168.88.3 subnet mask 255.255.255.0 gateway 192.168.88.1 on PC Run NetInstall (download page) Select \u0026ldquo;Net Booting\u0026rdquo; Mark \u0026ldquo;Boot Serve Enabled\u0026rdquo; Selected Client IP address of 192.168.88.1 Keep reset pressed while powering on Keep holding the reset pin till a beep sounds. Release immediately Router showed up in Netinstall\u0026rsquo;s list Unzipped \u0026ldquo;all_packages-mipsbe-X.X.zip\u0026rdquo; Selected need packages or all of them by browsing to the unzipped directory and using the \u0026ldquo;Select All\u0026rdquo; button Clicked on \u0026ldquo;Install\u0026rdquo; The progress bar moved to 100% as the packages were uploaded The router rebooted - Beep once, some time later (1 min or so if I recollect) a second beep    source oficial wiki  "});index.add({'id':24,'href':'/docs/misc/tips_and_tricks/','title':"Tips \u0026 Tricks",'section':"Docs",'content':"Common #  Generate password #  $ openssl rand -base64 14 $ gpg --gen-random --armor 1 14 $ cat /dev/urandom | tr -dc a-zA-Z0-9 | fold -w 14 | head -n 1 Generate missed pub key from private #  $ ssh-keygen -y -f ~/.ssh/id_rsa \u0026gt; ~/.ssh/id_rsa.pub Create a large file #   Linux \u0026amp; all filesystems  xfs_mkfile 10240m 10Gigfile  Linux \u0026amp; and some filesystems (ext4, xfs, btrfs and ocfs2)  fallocate -l 10G 10Gigfile  OS X, Solaris, SunOS and probably other UNIXes  mkfile 10240m 10Gigfile Source\nDate and time transformations #  # GNU date timestamp -\u0026gt; human-readable date -d @1339471282 human-readable -\u0026gt; timestamp date --date=\u0026#34;Tue 21 Jul 2020 03:56:50 PM MS\u0026#34; +\u0026#34;%s\u0026#34; # BSD date timestamp -\u0026gt; human-readable date -r 1282368345 human-readable -\u0026gt; timestamp date -j -f \u0026#34;%Y-%m-%d %H:%M:%S\u0026#34; \u0026#34;2018-01-30 15:58:50\u0026#34; \u0026#34;+%s\u0026#34; MySQL #  Change user pass #  ALTER USER \u0026#39;user\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;NEW_USER_PASSWORD\u0026#39;; FLUSH PRIVILEGES; Granting User Connections From Remote Hosts: #  GRANT ALL PRIVILEGES ON *.* TO \u0026#39;user\u0026#39;@\u0026#39;host\u0026#39; IDENTIFIED BY \u0026#39;my-new-password\u0026#39; WITH GRANT OPTION; Git #  Empty commit #  git commit --allow-empty -m \u0026#34;Empty commit message\u0026#34; Rename local branch #  git checkout ${TARGET_BRANCH} git branch -m ${NEW_BEANCH_NAME} Copy file from other branch #  git checkout ${SOURCE_BRANCH} /path/to/file Tmux #  :setw synchronize-panes Windows cmd #  reg - regestery managging tool\nreg query HKEY_LOCAL_MACHINE # shows all keys in selected branch wevtutil - shows Windiows logs\nwevtutil el # shows all available logs wevtutil qe ${LOG_NAME} # shows events from selected log systeminfo - provides software and hardware information\nWSL #  wsl -l -all # List of all available distros wsl -s ${distro_name} # Set a distro as default wsl --unregister ${distro_name} # Delete distro K8S #  Merge multiple kubectl configs into a single file #  # Make a copy of your existing config $ cp ~/.kube/config ~/.kube/config.bak # Merge the two config files together into a new config file $ KUBECONFIG=~/.kube/config:/path/to/new/config kubectl config view --flatten \u0026gt; /tmp/config # Replace your old config with the new merged config $ mv /tmp/config ~/.kube/config # (optional) Delete the backup once you confirm everything worked ok $ rm ~/.kube/config.bak "});index.add({'id':25,'href':'/docs/mooc/ml/','title':"Машинное обучение",'section':"Courses notes",'content':"Машинное обучение #  Введение в машинное обучение и основные понятия статистики #  Представление данных #  Данные представляются в виде таблицы, в которой:\n строки - объекты столбцы - признаки  Ограничение табличного представления данных - все объекты должны иметь одинаковое количество признаков.\nТипы признаков #   Количественный (числовой) - область значения - вещественные числа, сам имеет числовую природу Порядковый - задаёт порядок, последовательность объектов Номинальный (категориальный) - не имеет числовой природы, как правило, число возможных значений конечно.  Бинарный - частный случай номинального признака, имеющий два значения    Характеристики признаков #   максимальное и минимальное значения среднее арифметическое значение медиана - центральное значение в выборке, либо среднее от двух центральных значений, если количество элементов четное; значение медианы в том, что на нее не так сильно влияет попадание в выборку аномальных данных мода - наиболее часто встречающееся значение в выборке; в отличии от среднего и медианы имеет смысл и для номинальных признаков средне квадратичное отклонение (отклонение) - отражает отличие элементов выборки друг от друга, т.е. если все элементы одинаковы, отклонение - нулевое, в остальных случаях - положительное  всегда неотрицательное равно нулю, если все значение признака равны друг другу чем больше величина отклонения, тем сильнее разброс значений выборки относительно среднего значения   \\(\rS_p = \\sqrt{\\frac{1}{n-1}\\sum{i=1}_n(p_i - \\overline{p})^2}\r\\)      Если медианное и среднее значения близки друг к другу, выборка называется симметричной. В таких выборках проще искать аномалии.\nНа практике симметричной считается выборка, для которой выполняется неравенство:\n \\(\r|\\overline{p} - h_p| \\leqslant \\frac{3S_p}{\\sqrt{n}}\r\\)  Где  \\(h_p\\)  - медиана\nКоэффициент корреляции #  Коэффициент корреляции - величина, показывающая как значение одного признака определяет значение другого признака; такая величина должна иметь смысл и для признаков с разными единицами измерения.\nС геометрической точки зрения, КК - показатель того, как значения признаков ложатся на прямую.\nФормула КК:\n \\(\rr(P,Q) = \\frac{\\sum{i=1}^n {p_i}{q_i} - n\\overline{p}\\overline{q}}{(n-1){S_p}{S_q}}\r\\)  Свойства КК:\n принадлежит к отрезку [-1, 1] если равен нулю или близок к нему, то очевидной зависимости между признаками нет. КК \u0026gt; 0 - прямая зависимость между признаками КК \u0026lt; 0 - обратная зависимость чем ближе модуль КК к 1, тем зависимость (при 1, она линейная)  Восстановление пропущенных значений #  Виды повреждения данных:\n пустые (пропущенные) значения (заведомо) некорректные данные  Способы борьбы с пропусками данных:\n удаление объекта (строки) удаление столбца (в случае, если в нем много пустых объектов) замена значения в ячейке:  для числовых признаков:  среднее медиана   для номинальных признаков:  мода генерация случайного значения с учетом вероятности, основанной на имеющихся признаках приведение такого признака к числовому (может привести к появлению некорректных данных)      Метрика. Восстановление пропущенных объектов по их близости друг к другу #  Метрика - обобщение понятия расстояния из геометрии и может быть вычислена для объектов произвольной природы.\nДано два набора данных:\n \\(\rP = (p_1, p_2, ..., p_n)\rQ = (q_1, q_2, ..., q_n)\r\\)  Формулы вычисления метрики:\n Евклидова метрика (геометрическая формула расстояния между точками):   \\(\r\\rho(P,Q) = \\sqrt{(p_1 - q_1)^2 \u0026#43; (p_2 - q_2)^2 \u0026#43; ... \u0026#43; (p_n - q_n)^2}\r\\)  Метрика Манхеттен   \\(\r\\rho(P,Q) = |p_1 - q_1| \u0026#43; |p_2 - q_2| \u0026#43; ... \u0026#43; |p_n - q_n|\r\\)  Max-метрика   \\(\r\\rho(P,Q) = max(|p_1 - q_1|, |p_2 - q_2|, ..., |p_n - q_n|)\r\\)  Свойства метрики #   Расстояние от объекта до него же самого должно равняться нулю Расстояние от одного объекта до другого должно равняться обратному расстоянию Расстояние между двумя точками должно быть меньше чем сумма расстояний между этими точками и любой произвольной, не лежащей на прямой между ними (неравенство треугольника)  Формула восстановления данных с помощью метрики\n \\(\rP(A) = \\frac{1}{\\sum_{i=1}^n \\frac{1}{\\rho(A,A_i)}}(\\sum_{j=1}^n \\frac{P(A_j)}{\\rho(A,A_j)})\r\\)  Способы нормирования признаков #  Нормирование - приведение всех признаков к единому масштабу.\nПризнак:  \\(P = (p_1, p_2, ..., p_n)\\)   \\(\\overline{p}\\)  - среднее значение  \\(s\\)  - отклонение\n Приведение всех признаков в интервал [0, 1]:   \\(\rp\u0026#39; = \\frac{p_i - min(p_i)}{max(p_i)-min(p_i)}\r\\)  Выполнить преобразование, после которого среднее значение и отклонение признака будут равны 0 и 1:   \\(\rp\u0026#39;_i = \\frac{p_i - \\overline{p}}{s}\r\\)  Помимо приведенных формул, к значению признака можно предварительно применять различные функции, например логарифмирование.  Использование коэффициента корреляции для восстановления данных #  КК - выражает как сильно значение одного признака влияют на значения другого признака, т.е. меру близости признаков (т.е. столбцов таблицы). Метрика - выражает меру близости объектов (строк таблицы).\nФормула восстановления пропущенного значения с помощью среднего значения и КК:\nПусть P(A) - значение признака P объекта A  \\(\\overline{P}\\)  - среднее значение признака P Требуется определить P(A) по столбцам-признакам  \\(P_1, P_2, ..., P_m\\)   \\(\rP(A) = \\overline{P} \u0026#43; \\frac{\\sum_{j=1}^n r(P,P_i)(P_i(A) - \\overline{P_i})}{\\sum_{i=1}^m |r(P,P_i|)}\r\\)  Все вычисления проводятся без учета строки с пропущенным значением.\nПри использовании КК в работе с данными признаки можно не нормировать. КК также не изменится при изменении масштаба признаков и переводе в другие единицы измерения.\nПрименение метрик и КК в рекомендательных системах #  Алгоритмы восстановления данных можно использовать при проектировании рекомендательных систем.\nРекомендательная система:\n отслеживает историю действий пользователя выдает рекомендации на основе действий других пользователей, предпочтения которых соотносятся с целевым пользователем  С математической точки зрения это таблица, в которой:\n строки соответствуют пользователям столбцы - товарам на пересечении - оценка, которую пользователь поставил конкретному товару  Таким образом, задача рекомендательной системы сводится к восстановлению пропущенного значения в таблице.\nВ случае, если пользователи анонимны, мерой близости может служить информация о том, как часто те или иные товары попадают в один заказ.\nПоиск выбросов и аномалий #  Задача поиска выбросов (outlier detection) заключается в нахождении всех аномальных объектов в заданном множестве.\nВыброс - (зачастую) реально существующий объект, обладающий аномальными свойствами, сильно отличающийся от других объектов выборки.\n Если данные будут использоваться при решении задачи предсказания, то удаление выбросов, как правило, повышает точность предсказания Удаление выбросов позволяет получить нормальные (типичные, эталонные) объекты Многие характеристики (например, среднее значение) очень чувствительны к наличию выбросов  Идеальных методов обнаружения выбросов не бывает потому, что\u0026hellip;\n \u0026hellip; не существует формального определения выброса \u0026hellip; алгоритм, беспощадный к выбросам, будет удалять и часть \u0026ldquo;нормальных\u0026rdquo; объектов \u0026hellip; алгоритм, гуманный к \u0026ldquo;нормальным\u0026rdquo; объектам, будет пропускать часть выбросов  Методы обнаружения выбросов #   Поиск аномальных объектов с помощью здравого смысла; например, если известен нормальный диапазон для значений признака. Методы, основанные на анализе одного признака (каждый признака берётся отдельно и ищутся объекты с аномальными значениями этого признака). Методы, основанные на одновременном анализе нескольких признаков.  Методы, анализирующие признаки по отдельности #  Дано:  \\(P = (p_1, p_2, ..., p_n) \\)  Где,\n \\(\\overline{p} - среднее значение\\)   \\(n - объём выборки\\)   \\(S_p - отклонение\\)  Основная идея поиска аномалий - найти значения  \\(p_i\\)  , расположенные вдали от среднего значения или медианы.\nПростейшие методы поиска:\n Удалить все объекты, у которых величина  \\(|p_i - \\overline{p}|\\)  слишком велика (этот метод не учитывает величину отклонения признака; для некоторых признаков большой показатель отклонения это норма) Удалить все объекты, у которых величина  \\(\\frac{|p_i - \\overline{p}|}{S_p}\\)  слишком велика Более продвинутый критерий Шовене Определение выбросов без использования среднего и отклонения  Простое правило для определения выброса (второй метод) #   Пусть X - подозрительное значение Исключим X из выборки и по оставшимся элементам вычислим среднее и отклонение Если выборка симметричная, то X будет выбросом, если он не принадлежит интервалу  \\(\r(\\overline{p} - 3S_p, \\overline{p} \u0026#43; 3S_p)\r\\)   Если выборка не симметричная, то X будет выбросом, если он не принадлежит интервалу  \\(\r(\\overline{p} - 5S_p, \\overline{p} \u0026#43; 5S_p)\r\\)    Критерий Шовене (Chauvenet) #  Значение  \\(p_i\\)  является выбросом, если выполнено неравенство\n \\(erfc(\\frac{|p_i - \\overline{p}|}{S_p}) \\le \\frac{1}{2n}\\)  Где  \\(erfc(x) = \\frac{2}{\\sqrt{\\pi}}\\int_x^\\infty e^{-t^2}dt\\)  дополнение функции ошибок\nЭтот алгоритм применяется итерационно до тех пор, пока в выборке не перестанут находиться аномалии.\nПоиск выбросов без использования среднего и отклонения #  Значение среднего и отклонения, сильно чувствительны к наличию выбросов. Таким образом, возникает замкнутый круг: мы ищем выбросы с помощью характеристик, чьи значения обусловлены наличием выброса.\nКвартили:\n 1-ая квартиль  \\(Q_{25}\\)   - это такое число, что ровно 25% выборки меньше его 2-ая квартиль  \\(Q_{50}\\)   - это такое число, что ровно 50% выборки меньше его (фактически это медиана) 3-ая квартиль  \\(Q_{75}\\)   - это такое число, что ровно 75% выборки меньше его  Таким образом, 50% выборки принадлежат интервалу  \\([Q_{25}, Q_{75}]\\)  , их можно считать \u0026ldquo;эталонными\u0026rdquo;. Соответственно, элементы, достаточно удаленные от этого интервала можно считать выбросами.\nЕсли элемент не попадает в интервал:  \\(\r(Q_{25} - 1,5*(Q_{75} - Q_{25}), Q_{75} \u0026#43; 1,5*(Q_{75} - Q_{25}))\r\\)  то он является выбросом.\nМетоды, анализирующие несколько признаков #   необходимы в случаях, когда аномальное значение сходно, к примеру, со средним между нормальными значениями аномалии могут характеризоваться не только экстремальными значениями одного признака, но и нестандартными комбинациями нескольких признаков (например, сами по себе вес в 100 кг и рост 150 см не являются аномалиями, но их сочетание у одного объекта - является)   Метрические методы   опираются на функцию расстояния, то есть на метрику основная идея: у выброса мало соседей, а у типичного объекта много  для каждого объекта находится расстояние до всех остальных объектов и определяется ближайший сосед если расстояние от объекта до ближайшего соседа велико, то такой объект - аномалия    Геометрические методы   объекты проецируются на n-мерное пространство (например, на плоскость, в случае, если объекты могут быть описаны двумя признаками) строится выпуклая оболочка - многоугольник (для двумерного пространства) или многогранник, который неким образом описывает точки аномалиями в данном случае будут точки, лежащие на оболочке  Поиск с помощью кластеризации   при этом, объекты будут разделены на группы по некоторому признаку (или их сочетанию) при таком подходе выбросами считаются элементы малых (в том числе одноэлементных групп)  Поиск с помощью моделей предсказания   некоторые вариации метода опорных векторов (SVM) вариация решающих деревьев (decision trees) под названием \u0026ldquo;изолирующий лес\u0026rdquo; с помощью произвольной модели предсказания некоторого признака P по другим признакам таблицы  в этом случае выбросом будет тот объект, для которого предсказанное и имеющееся значения разойдутся очень сильно    Кластеризация (clustering) #  Задача алгоритма кластеризации состоит в разбиении множества данных объектов на несколько групп(кластеров), состоящих из похожих друг на друга объектов.\nЗадачи кластеризации:\n вычисления степени сходства объектов упрощение дальнейшей обработки данных (обработка меньших групп данных) сокращение объема хранимых данных за счет оставления одного представителя (эталона) от каждого кластера (задача сжатия данных) поиск выбросов разбиение признаков на кластеры и оставление по одному признаку из каждого кластера (отбор признаков)  Типы алгоритмов:\n разбивающие данные на заданное число кластеров (то есть число кластеров - входной параметр алгоритма)   пример: алгоритм k-means недостатки:  человеческий фактор(проблемы с предсказанием верного количества конечных кластеров)    в которых число кластеров не определено заранее, а вычисляется самим алгоритмом   пример: алгоритм FOREL недостатки:  алгоритм может выдать слишком много(мало) кластеров; в этом случае вся операция бесполезна    Если алгоритм кластеризации использует метрику на множестве объектов, то значения всех признаков необходимо предварительно нормировать!!1!  Кластеризация с помощью графов #  Данные представляются в виде графа, где:\n вершина - объект ребро - расстояние между объектами  Соответственно перед построением графа необходимо вычислить расстояния между каждой парой объектов\nОписание алгоритма:\n На вход алгоритма подается некоторое число R Из графа удаляются все ребра, метрики которых \u0026gt; R Оставшиеся после этого связными компоненты графа являются кластерами  Описание второго алгоритма\n На вход подается желаемое число кластеров k Строится остовное дерево (это подграф, содержащий все вершины исходного графа и не имеющий циклов) c минимальной суммарной длиной ребер; для этой задачи могут применяться:   алгоритм Краскала алгоритм Прима  Удаляем из дерева k-1 самых длинных ребер В один кластер попадают вершины из связанных компонент  Алгоритм FOREL (формальный элемент) #  Главное свойство алгоритма - количество кластеров не определено заранее Идея - найти точки сгущения объектов и объявить эти сгущения кластерами\nОписание алгоритма:\n На вход подается число R Представление данных: объекты представляются точками в пространстве  \\(R^m\\)  , где m - количество признаков объекта   В произвольную точку пространства добавляем формальный объект F (отсюда и название) Пусть K - все объекты, до которых расстояние от F меньше R Находим центр тяжести объектов из множества K и переносим туда объект F. Переходим к шагу 2   итерируемся по шагам 2-3 до тех пор, пока множество K не стабилизируется (то есть в него перестанут добавляться новые элементы и удаляться старые)  После стабилизации множество K объявляется новым кластером и объекты, попавшие в него удаляются из выборки Возвращаемся на шаг 1, если выборка не пуста, иначе алгоритм завершается  Центр тяжести - точка, координаты которой совпадают со средним значением признака.\nАлгоритмы k-means (k-средних) #   Главное свойство: количество кластеров k определено заранее Идея реализации: одновременно происходит поиск всех центров кластеров  Описание алгоритма (одна из реализаций):\n Вход: число кластеров k Представление данных: объекты представляются точками в пространстве  \\(R^m\\)  , где m - количество признаков объекта   Генерируем k случайных точек - центры кластеров Объект будет отнесен к тому кластеру, чей центр расположен ближе всех к этому объекту В получившихся кластерах центр переносится в центр тяжести, возврат на шаг 2   шаги 2-3 повторяются до тех пор, пока центры кластеров не стабилизируются  Недостатки алгоритма:\n результат зависит от выбора исходных центров кластеров, их оптимальный выбор неизвестен  Выбор оптимального числа кластеров #  Эта проблема актуальна для алгоритмов, в которых число кластеров является входным параметром.\nИдея - будем перебирать значения k, пока \u0026ldquo;качество кластеризации\u0026rdquo; не стабилизируется.\n Пусть  \\(S_k\\)  - сумма расстояний от объектов до центров их кластеров (при условии, что объекты разбиты на k кластеров). Тогда величину  \\(|S_{k\u0026#43;1} - S_k|\\)  можно рассматривать как увеличение качества кластеризации при переходе от k кластеров к (k+1) кластеру. Таким образом, \u0026ldquo;качество кластеризации\u0026rdquo; стабилизируется для такого k, где величина  \\(|S_{k\u0026#43;1} - S_k|\\)  становится небольшой.  Кластеризация по столбцам #  Транспонирование - зеркальное отображение таблицы отнисительно ее диагонали; операция, позволяющая поменять местами строки и столбцы, в нашем случае - объекты и признаки.\nСобственно сама кластеризация по столбцам выполняется в два шага:\n данные транспонируются применяется один из стандартных алгоритмов кластеризации  Назначение:\n позволяет найти близкие (по значению) друг к другу признаки. Можно из каждого кластера оставить по одному признаку и тем самым уменьшить размер данных это оправдано, так как слишком большое число признаков часто мешает анализу данных  Задача предсказания, линейная регрессия #  Предсказание (prediction):\n есть множество объектов M с известными значениями признака Y (целевой признак) требуется найти Y для нового объекта  \\(A \\notin M\\)    Задачи предсказания:\n Предсказание количественного признака Y называется задачей регрессии Предсказание номинального (категориального) признака Y называется задачей классификации  План решения задачи регрессии #  Общий план решения:\n множество объектов разбить на 2 множества:  тренировочную выборку (Train) тестовую или проверочную выборку (Test)   модель предсказания будет строиться по объектам Train, а качество проверяться объектам Test  Показатели качества регрессии:\n MAE (средняя абсолютная ошибка):   \\(\rMAE = \\frac{1}{n} \\sum_{i=1}^n{|y_i - y\u0026#39;_i|}\r\\)  Где:\n \\(n - объем тестовой выборки\\)   \\(y_i - истинные значения\\)   \\(Y\u0026#39;_i - предсказанные значения\\)  MAPE (средняя абсолютная ошибка в процентах):   \\(\rMAPE = \\frac{1}{n} \\sum_{i=1}^n{\\frac{|y_i - y\u0026#39;_i|}{|y_i|}} * 100\\%\r\\)  Модель регрессии не обязана давать точный ответ на объектах тренировочной выборки, так как модель не запоминает значения признаков тренировочной модели, а выстраивает зависимость между значениями целевого и нецелевых признаков.  Принцип работы модели (линейной) регрессии:\nУзлы - это объекты тренировочной выборки\nПредсказываться значения Y в новых точках можно с помощью:\n ломаной линии (линия, соединяющая все точки, лежащие на пересечении целевого и нецелевого признаков)  недостатки:  модель предсказания имеет сложность сравнимую с объемом данных модель нельзя проинтерпретировать нет уверенности, что на тестовой выборке будут небольшие ошибки эту модель нельзя экстраполировать     прямой регрессии, проходящей примерно посередине между объектами  Модель регрессии называется линейной, если значение предсказываемого признака Y вычисляется как сумма известных признаков  \\(X_1, X_2,... X_m\\)  , взятых с некоторыми коэффициентами\n \\(\ry\u0026#39; = w_1x_1 \u0026#43; w_2x_2 \u0026#43; ... \u0026#43; w_mx_m \u0026#43; w_0\r\\)  Задача заключается в нахождении оптимальных весов (коэффициентов)  \\(w_i\\)  .\nПринцип: для объектов тренировочной выборки нужно минимизировать отклонение предсказываемых значений от истинных значений признака Y.\nЛинейная регрессия неустойчива к выбросам, соответственно, их необходимо удалять заранее.  Построение модели линейной регрессии #  Отклонение истинного от предсказанного значения равно  \\(|y\u0026#39; - y| = |w_1x \u0026#43; w_0 - y|\\)  . Эту величину нужно минимизировать для всех объектов тренировочной выборки.\nПоиск точки минимума этой функции осложняется тем, что модуль-функция - недифференцируемая. Поэтому на практике минимизируют несколько иную функцию: сумму квадратов отклонений. Для нахождения точки минимума применяют частные производные.\nВ общем случае:\nКогда нецелевых признаков больше одного, все происходит аналогично, только параметров  \\(w_i\\)  будет больше (и полученная зависимость  \\(y\u0026#39;=...\\)  будет уже определять не прямую, а гиперплоскость).\nТаким образом, основная трудоемкость при построении линейной регрессии заключается в решении системы линейных уравнений на последнем шаге.\nПроблемы модели линейной регрессии #  Получаемая при построении линейной регрессии система линейных уравнений может:\n Не иметь решений Иметь более одного решения  Такие проблемы возникают, когда между нецелевыми признаками существует линейная зависимость или высокая корреляция. Такую проблему еще называют \u0026ldquo;проблемой мультиколлинеарности\u0026rdquo;.\nНапример, в случае, если значения нецелевых признаков совпадают, на выходе мы фактически получим систему, в которой неизвестных больше, чем уравнений (потому что несколько уравнений будут идентичны), а такая система имеет бесконечное количество решений.\nПроблемы системы с бесконечным количеством решений:\n зависимость целевого признака Y никак нельзя проинтерпретировать (так как любая выбранная модель будет одинаково хороша или плоха) возможна большая ошибка на объектах, не попавших в тренировочную выборку; это произойдет, когда в качестве коэффициентов будут выбраны большие числа  Советы по поиску хорошей модели регрессии:\n Отбор признаков. Нужно удалять нецелевые признаки, которые линейно зависят от других или имеют высокую корреляцию с другими признаками Коэффициент регрессии можно минимизировать (\u0026ldquo;регуляризация\u0026rdquo; и \u0026ldquo;лассо\u0026rdquo;)  Обобщение модели линейной регрессии:\n Регуляризация (Ridge-regression)  Основная идея:\n нужно стремиться сделать коэффициент регрессии минимальным величины весов также должны быть минимальными (по модулю)  Способ минимизации:\n \\(\rR = L(w_0, w_1, w_2, ..., w_m) \u0026#43; C(w_0^2, w_1^2, w_2^2, ..., w_m^2)\r\\)  Где C - заданная константа\nЛассо  Полиноминальная регрессия #  "});index.add({'id':26,'href':'/docs/mooc/sams_cv/week1/','title':"Нейрон и нейронная сеть",'section':"Нейронные сети и компьютерное зрение",'content':"Нейрон и нейронная сеть #  Строение биологического нейрона: #   ядро (тело) нейрона дендриты (малые отростки; служат для приема сигнала от других нейронов) аксон (большой отросток; служит для передачи сигнала к другим нейронам) синапс (соединение аксона одного нейрона с дендритом другого нейрона; изменяется со временем, в зависимости от обстоятельств может становиться сильнее или слабее)  сильный (обеспечивает практически полную передачу электрического сигнала) слабый (практически не передает сигнал)    Тренировка биологической нейронной сети заключается в настройке синапса.\nНейрон накапливает заряд до определенного предела и только после этого сигнал уходит по аксону к дендритам других нейронов.\nМатематическая модель нейрона #   сумматор вход выход функция активации (аналог механизма накопления заряда) синаптический вес (коэффициент входящего сигнала; настраиваемый параметр) смещение (настраиваемый параметр)    \\(y = f(z) = f(w_0x_0 \u0026#43; w_1x_1 \u0026#43; w_2x_2 \u0026#43; b) = f(\\lang w,x \\rang \u0026#43; b)\\)  Где:\n y - выходное значение z - результат работы сумматора f(z) - функция активации w - синаптический вес x - входное значение b - смещение  \u0026lt;\u0026gt; - скалярное произведение\nФункция активации #   Пороговая (аналогична существующей в биологическом нейроне)   \\(x = \\begin{cases} 0 \u0026amp;\\text{if } x \u0026lt;= 0 \\\\ 1 \u0026amp;\\text{if } x \u0026gt; 0 \\end{cases}\\)  Разделяющая поверхность - точка, в которой функция меняет значение с 0 на 1. В этой точке аргумент функции активации равен 0. Это плоскость, которая задается вектором w и смещением b. Положительное значение функции по отношению к разделяющей поверхности сонаправлено с вектором w.\nСигмоида   \\(\\sigma(x) = \\dfrac{1}{e^{-x}} \\\\ \\sigma(x) \\rarr 1 \\text{ if } x \\rarr \\infin \\\\ \\sigma(x) \\rarr 0 \\text{ if } x \\rarr -\\infin \\\\\\)  Если ввести параметр температуры (Т), появляется возможность регулировать наклон сигмоиды. При низких значениях температуры график сигмоиды стремится к графику пороговой функции.\n \\(\\sigma(x) = \\dfrac{1}{e^{\\frac{-x}{T}}}\\)  Нейронные сети #  При объединении нейронов между собой разделяющая поверхность перестаёт быть линейной и может, в том числе, образовывать несвязанные друг с другом области.\nКомбинировать полносвязанные линейные нейроны бессмысленно.\nДоп материалы #   Нейроны не любят одиночество Рост отростков одного нейрона Биологический нейрон (учебный фильм СССР) Частная жизнь нейрона 1987 (учебный фильм СССР) Нейроны мозга (Discovery) Science - Structure of Neuron_New Inside the Brain: Unraveling the Mystery of Alzheimer\u0026rsquo;s Disease [HQ] Transport inside the brain: The basic mechanisms of neuronal trafficking  "});index.add({'id':27,'href':'/docs/mooc/sams_cv/','title':"Нейронные сети и компьютерное зрение",'section':"Courses notes",'content':"Конспект курса #  Нейронные сети и компьютерное зрение\n"});index.add({'id':28,'href':'/docs/mooc/sams_cv/week2/','title':"Строим первую нейронную сеть",'section':"Нейронные сети и компьютерное зрение",'content':"Строим первую нейронную сеть #  Восстановление зависимостей #  Размеченная обучающая выборка состоит из объектов, для которых мы знаем:\n некоторые признаки метку объекта  Хорошей практикой является разделение датасета на три поддатасета:\n train (используется непосредственно для обучения модели) valid (используется для подстраивания параметров обучения нашей модели) test (используется для проверки окончательного результата)  Компоненты нейронной сети #   Архитектура нейронной сети Функции потерь (способ определения результата работы создаваемой сети; минимум этой функции соответствует оптимально настроенной сети) Метод оптимизации (говорит о том, как именно нужно изменить настройки сети для минимизации функции потерь) Метрики (показывают насколько успешно сеть решает поставленную задачу; например: точность; в отличии от функции потерь могут быть не дифференцируемыми)  Результирующая зависимость - сумма сигмоидных функций с соответствующими параметрами.\nФункция потерь #  Для задач восстановления скрытых зависимостей зачастую в качестве функции потерь используют функцию среднего квадрата ошибки (MSE, mean squared error):\nMSE=(1/N)*sum_N_i=1(y_av_i - y_i)^2 где:\n y_av_i - результат работы сети y_i - целевые значения  То есть это сумма квадратов отклонения полученных результатов от ожидаемых значений.\nАлгоритмы настройки нейронной сети #  Градиентный спуск #  w0 - вектор весов, который содержит все значения весов и смещений, которые используются в сети.\nГрадиент функции потерь - вектор, состоящий из производных по каждой из координат функции. Градиент указывает в сторону наибольшего роста функции потерь =\u0026gt; требуется сделать шаг из точки w0 в направлении обратном направлению градиента. Далее шаги повторяются.\nГрадиентный спуск находит минимум функции, но не гарантирует нахождения оптимального минимума.\nОграничения, накладываемые на функцию потерь:\n должна быть дифференцируемой (если в некотором множестве точек производная не определена, ее можно доопределить) производная функции потерь не должна быть равна нулю в большинстве точек  Правило цепочки (правило производной сложной функции) #  Граф вычисления - порядок вычисления сложной функции.\nпересмотреть\n"});index.add({'id':29,'href':'/docs/cloud/','title':"Cloud",'section':"Docs",'content':"Notes about clouds #  "});})();